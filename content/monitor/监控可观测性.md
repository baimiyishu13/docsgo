+++
title = '监控可观测性'
date = 2024-04-02T09:42:02+08:00
draft = true

+++

## 监控简述

### 概述

一个技术的出现必定有它的原因（解决了什么问题）

在现代的 DevOps 中手动处理变得越来越复杂，因此需要更多的自动化；

通常会拥有：

1. 多个项目、多个集群
2. 运行非常多的容器，并且有成千上百的不同进程在运行
3. 基础设施和 应用是相连的

因此需要去保持这样的设置去平稳运行、并且没有应用程序去停机，时间是非常重要的，也是有挑战性的。

需要解决：

1. 无法了解硬件级别或上层发生的情况
2. 应用程序级别、如 Error、响应延迟、硬件故障、或过载，可能耗尽资源等

在如此复杂的环境中，当部署大量的服务和应用程序时，可能出现很多问题，其中任何一个都可能导致程序崩溃，并且导致其他服务失败。

- 突然的应用程序对用户变得不可用，必须快速的确定这整个应用程序中是到底出现了什么问题
- 并且在手动调试过程中可能会很困难 且 耗时

### 示例场景

服务器内存不足，并启动了一个正在运行的容器，该容器在 `Kubernetes` 集群中两个数据库 `Pod` 之间提供数据，这反过来又导致：

1. 两个数据库部分失败，该数据库被身份验证服务器使用，该服务器也停止工作，因为数据库变得不可用
2. 然后依赖于该身份验证服务的应用程序无法再对 `UI` 中的用户进行身份验证
3. 用户角度：只看到 `UI` 中的错误，无法登陆

所以：遇到这种情况，如何知道实际上出了什么问题，对集群内部发生的情况如果看不到事件发生的整个事件链的红线，只看到错误，如何去排查修复，以便检查服务是否有返回并运行正常，是否现实异常，服务是否在正常运行，为什么会崩溃。

拥有一个工具使得搜索问题过程更加高效

1. 持续监控服务是否正常运行
2. 在一项服务崩溃时立即那个运维人员发出告警
3. 以便确切的知道发生了什么，甚至可以在问题发生前识别问题 提醒运维人员

例如在上述例子中，可以去定期检查每台 服务器的内存，做内存上限告警（当在一段时间内飙升到某个值，例如70%）或者不间断的去增加。

另外一种情况：突然停止看到应用程序的日志，因为 `elasticsear` 可接受的日志因为磁盘空间的不足或 `elasticsear` 再次达到为其分配的存储限制， 监控工具将 `持续检查磁盘空间` ，可以额告诉监控何时触发告警。

第三种情况：即应用程序由于一项服务奔溃而突然变得很慢，并开始在网络中循环发生数百条错误信息，这会产生高网络流量并减慢其他服务的速度，有一个工具可以检测网络负载中的此类峰值，并且告诉哪个服务负责导致的，可以及时发出告警 解决这个问题。

- 自动监控和警报：Promethers

监视特定的事物，该事物可以是如何东西，可以是整个Linux服务器、Windows服务器、也可以是独立的Apache服务器、单个应用程序 或 像数据库这样的服务，以及Prometheus 监视的哪些东西称为`目标`.

每个`目标`（targets）都有Linux serevr的监视单位，可以是 CPU、内存、磁盘、网路等，也可以是异常数据请求、请求持续时间以及 想要监视的目标的单位称之为 `指标`，指标是保存着 TSDB

### 收集指标

一个有趣的问题：如何去从目标收集这些指标

1. `prometheus` 从 `http` 端点从 `metrics` 中提取指标数据
2. 默认情况下是 `主机IP+端口:/metrics`
3. 目标必须公开`/metrics`接口，且必须采用 `prometheus`能够理解的格式

一些服务本身有`/metrics` 一些没有，因此需要额外的组件来执行此操作 ，该组件是导出器 `Exporter`

- Exporter：基本上是一个脚本，或者一个服务，用于从端点获取指标目标，并以`prometheus` 能够理解的格式转换它，并在自己的 `/metrics` 上公开它们（这些转换后的数据）。

### 优势

从端点提取数据是 `prometheus` 的一个重要的特征

推送系统：应用程序和服务器将指标 推送 到监控的集中收集平台， 当使用许多微服务，并且每个服务将其指标推送，会在基础设施产生高流量负载，来自所有服务的推送将造成基础设施超载，从而淹没网路，还必须在每个目标上安装守护进程。

prometheus 只需要一个抓取端点，这样指标就可以由多个prometheus 实例抓取，另一个优点是使用 `pull` 可以轻松检测到服务是否启动并正常运行，例如在拉取时没有响应 或者 当服务推送是时端点不可用时不推送如何数据或发送健康数据，除了服务未运行之外可能还有很多原因，网路不可达、或者其他的一些问题



## 可观测性体系概述

云原生监控可观测性是指在云原生架构中，通过使用各种工具和技术来实现对应用程序和基础设施的监控告警、故障排除等功能的一套完整的解决方案。

可观测性架构分层和主要的可观测能力:

![观测体系](/images/image-20240402133739885.png "Title")

### 数据采集

**指标采集：**提供基于Prometheus的云原生监控插件，相比于开源版本，具备轻量化，开箱即用等优势。[云原生监控插件](https://prometheus.io/docs/instrumenting/exporters/)

### 数据监控

victoriaMetrics：是一个支持高可用、经济高效且可扩展的监控解决方案和时间序列数据库，可用于 Prometheus 监控数据做长期远程存储。实时监控相关资源，分析健康状态，提供灵活丰富的数据可视化功能，帮助及时发现故障，全面掌握实时运行状况。

### 监控告警

alertmanager：它支持丰富的告警通知渠道，而且很容易做到告警信息进行去重，降噪，分组等，是一款前卫的告警通知系统。通过在定义告警规则，周期性的对告警规则进行计算，如果满足告警触发条件就会向 Alertmanager 发送告警信息。

### 数据观测

Grafana：是一个可视化面板，有着非常漂亮的图表和布局展示，功能齐全的度量仪表盘和图形编辑器，支持 Graphite、zabbix、InfluxDB、Prometheus、OpenTSDB、Elasticsearch 等作为数据源，比 Prometheus 自带的图表展示功能强大太多，更加灵活，有丰富的插件，功能更加强大。



## 监控系统概述

监控系统是可实时监控应用及资源，采集各项指标及事件等数据以分析健康状态，提供全面、清晰、多维度数据可视化能力，兼容主流开源组件，并提供快捷故障定位的能力。

### 功能介绍

**洞察力**：提供了采集主机信息，采集数据库信息，以及Kubernetes原生类型的容器监控能力，支持集群、节点、工作负载、容器组和事件的监控。

**仪表盘：**仪表盘可将不同图表汇聚到同一个屏幕上，通过不同的仪表形式来展示资源数据，进而全面、深入地掌握监控数据。



### 优势

- 监控中心深度整合监控项目victoriaMetrics。对关键指标、事件等运维数据进行统一采集、存储和可视化展现，精心打造云原生应用的良好可观测性能力。
- 将基础设施监控和应用负载监控进行关联，提供全栈监控，能够随时随地清晰地感知基础设施和应用负载状态。
- 能够对Kubernetes集群、节点、容器组（Pod）等进行详细监控，对业务提供端到端追踪和可视化，提供集群健康诊断能力，大大缩短问题分析定位时间。
- 提供开箱即用的插件安装、数据采集、云原生监控能力，相比基于开源组件构建的监控能力，在可靠性、高可用、安装部署便捷性上更具有竞争力，能够更好地为应用保驾护航。
- 提供了轻量化的指标采集插件，和社区Prometheus相比，资源使用量大大降低，部署模式方便快捷。

### 监控中心架构

![观测体系](/images/image-20240402103526012.png "Title")



监控插件将在用户集群中采集exporter暴露的指标，通过vmagent RemoteWrite的方式，将数据写入至VictoraMetrics实例。

监控中心将基于VictoraMetrics实例中存储的指标，提供容器洞察、健康诊断、仪表盘的功能。

将集群内的监控指标通过Token认证鉴权的方式上报三方监控平台，并且做TLS数据加密。



### VictoraMetrics监控

[VictoriaMetrics(VM)](https://victoriametrics.com/) 是一个支持高可用、经济高效且可扩展的监控解决方案和时间序列数据库，可用来解决 Prometheus 的高可用和远程存储的问题，是一个可水平扩容的本地全量持久化存储方案，VictoriaMetrics 不仅仅是时序数据库，它的优势主要体现在一下几点。

- 对外支持 Prometheus 相关的 API，可以直接用于 Grafana 作为 Prometheus 数据源使用
- 指标数据摄取和查询具备高性能和良好的可扩展性，性能比 InfluxDB 和 TimescaleDB 高出 20 倍
- 在处理高基数时间序列时，内存方面也做了优化，比 InfluxDB 少 10x 倍，比 Prometheus、Thanos 或 Cortex 少 7 倍
- 高性能的数据压缩方式，与 TimescaleDB 相比，可以将多达 70 倍的数据点存入有限的存储空间，与 Prometheus、Thanos 或 Cortex 相比，所需的存储空间减少 7 倍
- 它针对具有高延迟 IO 和低 IOPS 的存储进行了优化
- 提供全局的查询视图，多个 Prometheus 实例或任何其他数据源可能会将数据摄取到 VictoriaMetrics



## 接入监控中心

接入监控中心将在集群中安装监控插件，该插件提供监控中心的指标采集功能。安装后将采集集群中的指标并上报监控中心VictoriaMetrics。

### 前提条件

接入监控前，需要用户集群可以访问IP 1.15.176.240 端口8427 。

### 接入监控中心

前提：向管理员获取 Token 和 TLS证书。

+ **安装VMAgent** （worker节点）

  1. 下载包

  ```
  wget https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.99.0/vmutils-linux-amd64-v1.99.0.tar.gz
  ```

  2. 证书文件放置在 `/etc/ssl/certs`

  ```sh
  cert.pem  key.pem
  ```

  3. 创建目录 /data 已存在则忽略，减压`vmutils-linux-amd64-v1.99.0.tar.gz` 到 `data` 目录

  ```sh
  mkdir /data
  tar -zxvf vmutils-linux-amd64-v1.99.0.tar.gz -C /data
  ```

  4. 创建配置文件, `datacenter` 标签用于区分环境 【需添加两个标签】

  ```sh
  cat <<EOF >/data/vmagent.yml
  global:
    external_labels:
      datacenter: test # 环境标签1
      heihutao: test   # 环境标签1
  scrape_configs:
    #- job_name: node-exporter # 监控节点
    #  static_configs:
    #  - targets: ['1.1.1.1:9101'，'1.1.1.2:9101']  # 监控节IP
  EOF
  ```

  5. Systemd创建Linux服务, `$Token` 替换成从管理员获取的`Token`

  ```sh
  cat <<EOF > /etc/systemd/system/vmagent.service 
  
  [Unit]
  Description=vmagent
  After=network.target
  
  [Service]
  Type=simple
  ExecStart=/data/vmagent-prod -tls -tlsCertFile=/etc/ssl/certs/cert.pem -tlsKeyFile=/etc/ssl/certs/key.pem -remoteWrite.bearerToken=$Token -promscrape.config=/data/vmagent.yml -remoteWrite.url=https://1.15.176.240:8427/api/v1/write
  Restart=always
  
  [Install]
  WantedBy=multi-user.target
  
  EOF
  ```

  6. 启动服务

  ```sh
  systemctl start vmagent.service 
  systemctl status vmagent.service 
  systemctl enable vmagent.service 
  ```

### 采集指标组件安装

当前可安装监控数据采集组件

| 组件                   | 安装方式                                                     | 描述                                     |
| ---------------------- | ------------------------------------------------------------ | ---------------------------------------- |
| Kube State Metrics     | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/kube-state-metrics/) | 采集 Kubernetes 集群状态指标             |
| Node Exporter          | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/node-exporter/) | 采集主机级系统指标，如 CPU、内存、磁盘等 |
| Mysql Exporter         | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/mysql-exporter/) | 采集 MySQL 数据库指标                    |
| Elasticsearch Exporter | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/elasticsearch-exporter/) | 采集 Elasticsearch 集群的指标数据        |
| Mongodb Exporter       | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/mongodb-exporter/) | 采集 MongoDB 数据库的性能指标            |
| Etcd Exporter          | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/etcd-exporter/) | 采集 Etcd 的指标数据                     |
| Cassandra Exporter     | [安装链接](https://baimiyishu13.github.io/docsgo/monitor/exporter/cassandra-exporter/) | 采集 Cassandra 数据库的性能指标          |



## 使用仪表盘

仪表盘集合了不同视角、不同组件的高频监控指标。将不同的指标以图表的形式直观、综合性地汇集在屏幕上，帮助实时全面地掌握集群整体运行状况。

仪表盘提供了丰富的视图监控指标呈现，包括集群视图、数据库视图、主机视图、Node视图等等。

### 前提条件：

+ 已完成监控组件安装并且接入监控中心，处于 “运行中” 状态。
+ 从管理员获取访问账号

监控访问地址：https://monitor.com.cn:3000/

### 查看/切换视图

1. 登陆到Grafana控制台，点击左上角“首页”旁 “三”。
2. 在左侧导航栏中选择 “仪表盘”，单击“仪表盘”页签，选择需要查看的监控项
3. 设置视图的时间窗，在页面右上角处，选择时间段，或者自定义时间，并单击刷新界面。



## 监控告警

告警是可观测性体系里面比较重要的一环。在告警中，除了传统的CPU、内存等资源使用量的告警以外，还有容器重启等事件告警等自定义的监控指标告警。

告警中心架构

![观测体系](/images/image-20240402113713763.png "Title")



- 告警中心

  基于vmAlert服务和Alertmanager的告警能力实现，提供告警快速检索、告警快速配置的能力。

