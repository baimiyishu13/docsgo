+++
title = '第6章：高级管道：版本控制、缓存、多阶段……'
date = 2024-04-24T14:30:19+08:00
draft = true

+++

## 版本控制

当前我们构建的文件中，镜像版本

```yml
variables:
  GIT_DEPTH: 0
  IMAGE_NAME: $CI_REGISTRY_IMAGE
  IMAGE_TAG: "1.2"
  APP_PORT: 3001
```

如果不增加修改，将会一直是1.2，这样做不现实因为会产生覆盖。

生产环境中，每次管道构建都会产生一个新的版本

+ 随着程序改进，我们依然希望保留跟踪版本直接的变化

### 设置递增版本过程

版本 1.1.1

+ 第一个数字： 程序重大改动，重构，替换编码框架
+ 第二个数字：次要更改，新功能，大的bug修复
+ 第三个数字：补丁版本，小的修改，例如较小的bug修复



在 CI 文件中读取程序的 版本

+ 服务器安装 jq 命令

```sh
[root@monitor ~]# cat p.json   | jq -r '.version'
1.0.0
```



```yaml
build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export APP_VERSION=$(cat app/package.json | jq -r '.version')
  script:
    - docker build -t $IMAGE_NAME:$APP_VERSION .
```



即使这样，还需每次修改应用程序中的 version



在构建镜像是 为 Image 添加 TAG 【预定义变量】 

==CI_PIPELINE_IID==: 当前管道的项目级 IID

+ 将用作 TAG 版本的一部分

版本：`1.0.0-2378` 版本号-内部版本

或者将 构建 ID 作为第三个数：`1.0.buildID`

```yaml
build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export PACKAGE_JSON_VERSION=$(cat app/package.json | jq -r '.version')
    - export VERSION=$PACKAGE_JSON_VERSION.$CI_PIPELINE_IID
  script:
    - docker build -t $IMAGE_NAME:$VERSION .
```

此时的环境变量只能用于 build_image

不希望在每个任务中设置，避免冗余

+ artifacts：artifacts 关键字用于指定在作业运行后应保存的文件和目录。

生成一个变量文件，供其他任务使用

```yml
build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export PACKAGE_JSON_VERSION=$(cat app/package.json | jq -r '.version')
    - export VERSION=$PACKAGE_JSON_VERSION.$CI_PIPELINE_IID
    - echo $VERSION > version-file.txt
  script:
    - docker build -t $IMAGE_NAME:$VERSION .
  artifacts:
    paths:
      - version-file.txt
```



### 使用阶段的产物作为变量文件

**说明：**

阶段的产物下一阶段可以直接使用，但是在同一阶段中的任务

在 GitLab CI/CD 中，你可以使用 `dependencies` 关键字来指定一个作业依赖于哪些其他作业。这样，这个作业就可以使用那些作业的构建工件（artifacts）。默认情况下，一个作业会依赖于同一阶段中所有其他作业以及所有先前阶段中的作业。

然而，你可以使用 `dependencies` 关键字来更改这个行为。例如，你可以让一个作业只依赖于特定的作业，或者让一个作业不依赖于任何其他作业。

这是一个例子：

```yaml
job1:
  stage: build
  script: echo "This is job1" > file1.txt
  artifacts:
    paths:
      - file1.txt

job2:
  stage: test
  script: cat file1.txt
  dependencies:
    - job1
```

在这个例子中，`job2` 依赖于 `job1`，所以它可以使用 `job1` 的构建工件 `file1.txt`。

需要注意的是，`dependencies` 只能指定在当前作业之前的作业。你不能让一个作业依赖于同一阶段中的后续作业或者后续阶段中的任何作业。如果你需要在作业之间共享数据，你可能需要重新组织你的阶段和作业，或者使用其他方法（如使用外部存储）来共享数据。



push_image

```yml
push_image:
  stage: build
  needs:
    - build_image
  dependencies:
    - build_image
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export VERSION=$(cat version-file.txt)
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker push $IMAGE_NAME:$VERSION
```

如果有 needs 便不需要 dependencies，存在重叠功能

```yml
push_image:
  stage: build
  needs:
    - build_image
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export VERSION=$(cat version-file.txt)
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker push $IMAGE_NAME:$VERSION
```



如果在后面的阶段不需要 前面阶段的产物

```yml

test-dev:
  stage: deploy
  dependencies: [] # 不要下载先前阶段任何东西
  script:
    - echo "testing"
```



当前完整文件【实现了版本递增】

```yml
---
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH != "main" && $CI_PIPELINE_SOURCE != "merge_request_event"
      when: never
    - when: always

stages:
  - lint
  - test
  - build
  - deploy

variables:
  GIT_DEPTH: 0
  IMAGE_NAME: $CI_REGISTRY_IMAGE
  APP_PORT: 3001
  DEV_SERVER_HOST: "1.15.176.240"
  DEV_ENDPOINT: http://$DEV_SERVER_HOST:3001

lint_code_yaml:
  image: python:3.10
  stage: lint
  tags:
    - ec2
    - aws
    - docker
  script:
    - pip install yamllint
    - yamllint .

run_unit_test:
  image: node:21-alpine
  stage: test
  tags:
    - ec2
    - aws
    - docker
  before_script:
    - cd app
    - npm install
  script:
    - npm test
  artifacts:
    when: always
    paths:
      - app/junit.xml
    reports:
      junit: app/junit.xml

build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export PACKAGE_JSON_VERSION=$(cat app/package.json | jq -r '.version')
    - export VERSION=$PACKAGE_JSON_VERSION.$CI_PIPELINE_IID
    - echo $VERSION > version-file.txt
  script:
    - docker build -t $IMAGE_NAME:$VERSION .
  artifacts:
    paths:
      - version-file.txt

push_image:
  stage: build
  needs:
    - build_image
  dependencies:
    - build_image
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export VERSION=$(cat version-file.txt)
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker push $IMAGE_NAME:$VERSION

deploy_to_dev:
  stage: deploy
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - chmod 600 $SSH_PRIVATE_KEY
    - export IMAGE_TAG=$(cat version-file.txt)
  script:
    - echo $DC_IMAGE_NAME:$DC_IMAGE_TAG
    - scp -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY ./docker-compose.yaml root@$DEV_SERVER_HOST:/root
    - ssh -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY root@$DEV_SERVER_HOST "
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY &&
      export DC_IMAGE_NAME=$IMAGE_NAME &&
      export DC_IMAGE_TAG=$IMAGE_TAG &&
      docker-compose down &&
      docker-compose up -d"
  environment:
    name: development
    url: $DEV_ENDPOINT

```







### 将变量导出为环境变量

```yaml
- echo "MY_ENV=value" >> build.env
```

将 MY_ENV=value 保存到build.env文件

```yml
build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export PACKAGE_JSON_VERSION=$(cat app/package.json | jq -r '.version')
    - export VERSION=$PACKAGE_JSON_VERSION.$CI_PIPELINE_IID
    - echo $VERSION > version-file.txt
    - echo "VERSION=$VERSION" >> build.env
  script:
    - docker build -t $IMAGE_NAME:$VERSION .
  artifacts:
    reports:
      dotenv: build.env
```

意味着在接下来的阶段不需要使用 `export VERSION=$(cat version-file.txt)`

也不需要有下载产物



如果我们有多个环境变量，需要传递给多个的 Job，那么使用 .env 会非常方便，因为很难从文件中读取多个变量



## 缓存

### 管道中优化

+ 使 Job 更快、更高效 【这是配置CICD始终需要的东西 --缓存】

每个作业运行在独立环境



某些情况下，不同Job 需要共享一些文件。



例如，在单元测试时，npm install 安装依赖项

编译打包时也需要 npm install 安装，虽然是相同的依赖，但是不能重用。

如果，程序很复杂，并且package.json 中有很多依赖，如果是数百个，那么将会非常慢，花费大量时间。

+ 每个需要这些依赖的 Job 都会去占用宽带下载 【导致管道变慢】



1. 某种作业或多个作业来安装依赖，共享文件夹，【不必经历相同的过程】
2. 下一次管道运行，希望重用上一次管道运行的阶段模块

生产的产物将被上传到 gitlab server，然后会再下载以用于下一个 job。对于一两个文件没问题，但对于这些依赖项一堆文件，上传到gitlab server上不是一个很大的优化。仍然需要大量时间和宽带。

还需考虑，一旦拥有应用程序的第一个版本，不会经常去改依赖项，很长时间保持不变。

+ 团队每隔几分钟推送一次，产生大量的管道，使得运行不必要的依赖项下载，这将大大的加快管道执行速度



### Artifacts vs cache

Artifacts 将 产物上传到 gitlab server ，下一个job 可以下载使用

cache：存储项目所需的所有依赖项，在如何管道和Job之间传递，不像 产物上传到 gitlab server，

+ 存储在gitlab runner

当有多个 runner 时，如果有 100个 runner，Job 随机选择 runner，那么缓存的效率可能不高，因为需要在每个机器上建立缓存

+ 3s：还可以使用 对象存储，桶来存储，无论在哪个runner上执行，都一样
+ 意味着需要再次重 互联网下载



缓存实际上非常简单。

命名缓存常见：多个分支，并且分支可以运行管道作为缓存。

+ cache_main
+ cache_dev



CI_COMMIT_BRANCH ： 提交的分支名

```yml

run_unit_test:
  image: node:21-alpine
  stage: test
  cache:
    key: "$CI_COMMIT_BRANCH"
    paths:
      - app/node_modules
```

以便节点任何 Job 都可以使用。

```yml
run_unit_test:
  image: node:21-alpine
  stage: test
  cache:
    key: "$CI_COMMIT_BRANCH"
    paths:
      - app/node_modules
  tags:
    - ec2
    - aws
    - docker
  before_script:
    - cd app
    - npm install
  script:
    - npm test
  artifacts:
    when: always
    paths:
      - app/junit.xml
    reports:
      junit: app/junit.xml

run_lint_checks:
  image: node:21-alpine
  stage: test
  cache:
    key: "$CI_COMMIT_BRANCH"
    paths:
      - app/node_modules
    policy: pull						# 只允许 pull ，不能更新上传，默认pull-push
  tags:
    - ec2
    - aws
    - docker
  before_script:
    - cd app
    - npm install
  script:
    - echo "Running lint checks" 
```



缓存可以最前面建立缓存

```yaml
build_cache:
  cache:
    key: "$CI_COMMIT_BRANCH"
    paths:
      - app/node_modules
    policy: push
```



因为是在docker 创建缓存，所以

https://docs.gitlab.com/runner/configuration/advanced-configuration.html

配置：

`/etc/gitlab-runner/config.toml `

```sh
executor = "docker"
cache_dir = "/cache"
```

![image-20240424192635275](/images/image-20240424192635275.png "Title")



![image-20240424193327984](/images/image-20240424193327984.png "Title")

就缓存不会被删除，不会在新管道中使用，但是数据仍然在 gitlab runner 服务端

真删除：到runner 找到实际的缓存手动删除



缓存的实际物理位置：

docker volume

```sh
# docker volume inspect runner-qz4ygpw8m-project-57100451-concurrent-1-cache-c33bcaa1fd2c77edfc3893b41966cea8
```

![image-20240424194434799](/images/image-20240424194434799.png "Title")



## Testing SAST Job

足够的自动化测试，避免大量手动测试。

开发和测试：编写一个用于测试的应用程序不同方便面的大量自动化单元测试只是其中之一，最简单的测试

功能测试、集成测试，创建测试场景并且编写测试，等等程序偶寄功能测试。

安全性测试：安全问题、漏洞等等。

+ SAST：其中之一，静态程序安全测试，程序漏洞，如sql注入等等



当然，需不要会写测试，会用就行。

https://gitlab.com/gitlab-org/gitlab-foss/-/blob/master/lib/gitlab/ci/templates

![image-20240424211208444](/images/image-20240424211208444.png "Title")

复制文件Jobs/SAST.gitlab-ci.yml

```yml
sast:
  stage: test

include:
  - template: Jobs/SAST.gitlab-ci.yml
```



在的 `.gitlab-ci.yml` 文件中，`sast: stage: test` 定义了一个名为 `sast` 的任务，并将其阶段设置为 `test`。这意味着在 CI/CD 流程中，`sast` 任务将在 `test` 阶段执行。

然而，这个 `sast` 任务没有定义任何 `script` 或 `image`，所以它本身不会执行任何操作。但是在文件的末尾，您使用了 `include` 关键字来包含 `Jobs/SAST.gitlab-ci.yml` 模板。这个模板可能定义了 `sast` 任务的具体行为。

`SAST` 是静态应用程序安全测试的缩写，它是一种安全测试方法，用于在不运行程序的情况下，通过分析源代码、字节码或二进制代码来发现安全漏洞。在 GitLab 中，`SAST` 通常通过包含 `SAST.gitlab-ci.yml` 模板来实现，这个模板定义了一系列的 `sast` 任务，用于对各种语言的代码进行静态安全测试。

因此，`sast: stage: test` 与 `include: - template: Jobs/SAST.gitlab-ci.yml` 结合使用，会在 `test` 阶段执行静态应用程序安全测试。

 ![image-20240424214112636](/images/image-20240424214112636.png "Title")

下载产物，导入可视化软件；

![image-20240424214905506](/images/image-20240424214905506.png "Title")



## 多阶段

确保这些阶段没有安全问题，需要分阶段发布应用程序

阶段1:部署到 dev环境这个阶段，可以运行：集成和功能测试后程序仍然正常运行。

1. Function test
2. integration test

阶段2:：预生产环境 【性能测试】确保正常运行

1. Performance test
2. DAST test 【安全】

阶段3:生产环境

+ 实时终端环境



cicd ： 自动化管道完成所有



有条件：将会创建两个额外的 EC2 作为实验

无条件：应用程序使用不同端口，模拟多环境



为 docker-compose.yaml 中 port端口 - 变量

![image-20240425013533857](/images/image-20240425013533857.png  "Title")

```yml
---
version: "3.3"
services:
  app:
    image: ${DC_IMAGE_NAME}:${DC_IMAGE_TAG}
    ports:
      - "${DC_APP_PORT}:3000"

```

-

```yml
---
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH != "main" && $CI_PIPELINE_SOURCE != "merge_request_event"
      when: never
    - when: always

stages:
  - test
  - build
  - deploy_dev
  - deploy_staging

variables:
  GIT_DEPTH: 0
  IMAGE_NAME: $CI_REGISTRY_IMAGE
  DEV_SERVER_HOST: "1.15.176.240"
  DEV_ENDPOINT: http://$DEV_SERVER_HOST:3001
  STAGING_SERVER_HOST: "1.15.176.240"
  STAGING_ENDPOINT: http://$STAGING_SERVER_HOST:3002

run_unit_test:
  image: node:21-alpine
  stage: test
  cache:
    key: "$CI_COMMIT_BRANCH"
    paths:
      - app/node_modules
  tags:
    - ec2
    - aws
    - docker
  before_script:
    - cd app
    - npm install
  script:
    - npm test
  artifacts:
    when: always
    paths:
      - app/junit.xml
    reports:
      junit: app/junit.xml

sast:
  stage: test

build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export PACKAGE_JSON_VERSION=$(cat app/package.json | jq -r '.version')
    - export VERSION=$PACKAGE_JSON_VERSION.$CI_PIPELINE_IID
    - echo $VERSION > version-file.txt
    - echo "VERSION=$VERSION" >> build.env
  script:
    - docker build -t $IMAGE_NAME:$VERSION .
  artifacts:
    reports:
      dotenv: build.env

push_image:
  stage: build
  needs:
    - build_image
  dependencies:
    - build_image
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker push $IMAGE_NAME:$VERSION

deploy_to_dev:
  stage: deploy_dev
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - chmod 600 $SSH_PRIVATE_KEY
  script:
    - echo $DC_IMAGE_NAME:$DC_IMAGE_TAG
    - scp -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY ./docker-compose.yaml root@$DEV_SERVER_HOST:/root
    - ssh -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY root@$DEV_SERVER_HOST "
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY &&
      export COMPOSE_PROJECT_NAME=dev &&
      export DC_IMAGE_NAME=$IMAGE_NAME &&
      export DC_IMAGE_TAG=$VERSION &&
      export DC_APP_PORT=3001 &&
      docker-compose down &&
      docker-compose up -d"
  environment:
    name: development
    url: $DEV_ENDPOINT

run_functional_test:
  stage: deploy_dev
  needs:
    - deploy_to_dev
  tags:
    - ec2
    - aws
    - shell
  script:
    - echo "Running functional test"

deploy_to_staging:
  stage: deploy_staging
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - chmod 600 $SSH_PRIVATE_KEY
  script:
    - echo $DC_IMAGE_NAME:$DC_IMAGE_TAG
    - scp -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY ./docker-compose.yaml root@$STAGING_SERVER_HOST:/root
    - ssh -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY root@$STAGING_SERVER_HOST "
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY &&
      export COMPOSE_PROJECT_NAME=staging &&
      export DC_IMAGE_NAME=$IMAGE_NAME &&
      export DC_IMAGE_TAG=$VERSION &&
      export DC_APP_PORT=3002 &&
      docker-compose down &&
      docker-compose up -d"
  environment:
    name: staging
    url: $STAGING_ENDPOINT

include:
  - template: Jobs/SAST.gitlab-ci.yml

```



如果使用相同的部署代码，三个环境就需要重复三次！

所以：

### 配置清理代码重复

1. 创建一个通用的 JOB 【不让它执行】 使用 `.deploy`

2. extends 关键字用于从一个已定义的 job 中继承配置。这意味着你可以创建一个基础 job，然后在其他 job 中通过 extends 关键字来复用这个基础 job 的配置。

```yml
.deploy:
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - chmod 600 $SSH_PRIVATE_KEY
  variables:
    SSH_PRIVATE_KEY: ""
    SERVER_HOST: ""
    DEPLOY_ENV: ""
    APP_PORT: ""
    ENDPOINT: ""
  script:
    - scp -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY ./docker-compose.yaml root@$SERVER_HOST:/root
    - ssh -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY root@$SERVER_HOST "
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY &&
      export COMPOSE_PROJECT_NAME=$DEPLOY_ENV &&
      export DC_IMAGE_NAME=$IMAGE_NAME &&
      export DC_IMAGE_TAG=$VERSION &&
      export DC_APP_PORT=$APP_PORT &&
      docker-compose down &&
      docker-compose up -d"
  environment:
    name: $DEPLOY_ENV
    url: $ENDPOINT

deploy_to_dev:
  extends: .deploy
  stage: deploy_dev
  variables:
    SSH_PRIVATE_KEY: $SSH_PRIVATE_KEY
    SERVER_HOST: $DEV_SERVER_HOST
    DEPLOY_ENV: dev
    APP_PORT: "3001"
    ENDPOINT: $DEV_ENDPOINT

```

完整代码

```yml
---
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH != "main" && $CI_PIPELINE_SOURCE != "merge_request_event"
      when: never
    - when: always

stages:
  - test
  - build
  - deploy_dev
  - deploy_staging
  - deploy_prod

variables:
  GIT_DEPTH: 0
  IMAGE_NAME: $CI_REGISTRY_IMAGE
  DEV_SERVER_HOST: "1.15.176.240"
  DEV_ENDPOINT: http://$DEV_SERVER_HOST:3001
  STAGING_SERVER_HOST: "1.15.176.240"
  STAGING_ENDPOINT: http://$STAGING_SERVER_HOST:3002
  PROD_SERVER_HOST: "1.15.176.240"
  PROD_ENDPOINT: http://$PROD_SERVER_HOST:3003


run_unit_test:
  image: node:21-alpine
  stage: test
  cache:
    key: "$CI_COMMIT_BRANCH"
    paths:
      - app/node_modules
  tags:
    - ec2
    - aws
    - docker
  before_script:
    - cd app
    - npm install
  script:
    - npm test
  artifacts:
    when: always
    paths:
      - app/junit.xml
    reports:
      junit: app/junit.xml

sast:
  stage: test

build_image:
  stage: build
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - export PACKAGE_JSON_VERSION=$(cat app/package.json | jq -r '.version')
    - export VERSION=$PACKAGE_JSON_VERSION.$CI_PIPELINE_IID
    - echo $VERSION > version-file.txt
    - echo "VERSION=$VERSION" >> build.env
  script:
    - docker build -t $IMAGE_NAME:$VERSION .
  artifacts:
    reports:
      dotenv: build.env

push_image:
  stage: build
  needs:
    - build_image
  dependencies:
    - build_image
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker push $IMAGE_NAME:$VERSION

.deploy:
  tags:
    - ec2
    - aws
    - shell
  before_script:
    - chmod 600 $SSH_PRIVATE_KEY
  variables:
    SSH_KEY: ""
    SERVER_HOST: ""
    DEPLOY_ENV: ""
    APP_PORT: ""
    ENDPOINT: ""
  script:
    - scp -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY ./docker-compose.yaml root@$SERVER_HOST:/root
    - ssh -o StrictHostKeyChecking=no -i $SSH_PRIVATE_KEY root@$SERVER_HOST "
      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY &&
      export COMPOSE_PROJECT_NAME=$DEPLOY_ENV &&
      export DC_IMAGE_NAME=$IMAGE_NAME &&
      export DC_IMAGE_TAG=$VERSION &&
      export DC_APP_PORT=$APP_PORT &&
      docker-compose down &&
      docker-compose up -d"
  environment:
    name: $DEPLOY_ENV
    url: $ENDPOINT

deploy_to_dev:
  extends: .deploy
  stage: deploy_dev
  variables:
    SSH_PRIVATE_KEY: $SSH_PRIVATE_KEY
    SERVER_HOST: $DEV_SERVER_HOST
    DEPLOY_ENV: dev
    APP_PORT: "3001"
    ENDPOINT: $DEV_ENDPOINT

run_functional_test:
  stage: deploy_dev
  needs:
    - deploy_to_dev
  tags:
    - ec2
    - aws
    - shell
  script:
    - echo "Running functional test"

deploy_to_staging:
  extends: .deploy
  stage: deploy_staging
  variables:
    SSH_KEY: $SSH_PRIVATE_KEY
    SERVER_HOST: $STAGING_SERVER_HOST
    DEPLOY_ENV: staging
    APP_PORT: "3002"
    ENDPOINT: $STAGING_ENDPOINT

run_performance_test:
  stage: deploy_staging
  needs:
    - deploy_to_staging
  tags:
    - ec2
    - aws
    - shell
  script:
    - echo "Running production test"

deploy_to_prod:
  extends: .deploy
  stage: deploy_prod
  variables:
    SSH_KEY: $SSH_PRIVATE_KEY
    SERVER_HOST: $PROD_SERVER_HOST
    DEPLOY_ENV: production
    APP_PORT: "3002"
    ENDPOINT: $PROD_ENDPOINT

include:
  - template: Jobs/SAST.gitlab-ci.yml

```



### 配置手动审批

没有任何人工审查就之间部署到生产环境是不合理的。

因此管道会一直存在暂存和运行测试，但不会自动部署到生产环境【会等待人工确认】

```sh
when: manual
```

当一个 job 被设置为 when: manual，这个 job 不会在 pipeline 自动执行时被执行，而是需要手动触发。 

![image-20240425102402381](/images/image-20240425102402381.png "Title")
