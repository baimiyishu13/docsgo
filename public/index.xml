<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on docsGo</title>
    <link>http://localhost:1313/docsgo/</link>
    <description>Recent content in Home on docsGo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 May 2024 14:04:40 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/docsgo/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>10 Environment</title>
      <link>http://localhost:1313/docsgo/istio/10-environment/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/10-environment/</guid>
      <description></description>
    </item>
    <item>
      <title>11 Demo</title>
      <link>http://localhost:1313/docsgo/istio/11-demo/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/11-demo/</guid>
      <description></description>
    </item>
    <item>
      <title>12 Envoy</title>
      <link>http://localhost:1313/docsgo/istio/12-envoy/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/12-envoy/</guid>
      <description></description>
    </item>
    <item>
      <title>13 Telemetry</title>
      <link>http://localhost:1313/docsgo/istio/13-telemetry/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/13-telemetry/</guid>
      <description></description>
    </item>
    <item>
      <title>14 Management</title>
      <link>http://localhost:1313/docsgo/istio/14-management/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/14-management/</guid>
      <description></description>
    </item>
    <item>
      <title>15 Balancing</title>
      <link>http://localhost:1313/docsgo/istio/15-balancing/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/15-balancing/</guid>
      <description></description>
    </item>
    <item>
      <title>16 Gateways</title>
      <link>http://localhost:1313/docsgo/istio/16-gateways/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/16-gateways/</guid>
      <description></description>
    </item>
    <item>
      <title>3 Injection</title>
      <link>http://localhost:1313/docsgo/istio/3-injection/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/3-injection/</guid>
      <description></description>
    </item>
    <item>
      <title>4 Breaking</title>
      <link>http://localhost:1313/docsgo/istio/4-breaking/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/4-breaking/</guid>
      <description></description>
    </item>
    <item>
      <title>5 TLS</title>
      <link>http://localhost:1313/docsgo/istio/5-tls/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/5-tls/</guid>
      <description></description>
    </item>
    <item>
      <title>6 Istioctl</title>
      <link>http://localhost:1313/docsgo/istio/6-istioctl/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/6-istioctl/</guid>
      <description></description>
    </item>
    <item>
      <title>7 Istio</title>
      <link>http://localhost:1313/docsgo/istio/7-istio/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/7-istio/</guid>
      <description></description>
    </item>
    <item>
      <title>8 Goodbye</title>
      <link>http://localhost:1313/docsgo/istio/8-goodbye/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/8-goodbye/</guid>
      <description></description>
    </item>
    <item>
      <title>9 Started</title>
      <link>http://localhost:1313/docsgo/istio/9-started/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/9-started/</guid>
      <description></description>
    </item>
    <item>
      <title>第2章：Istio 入门</title>
      <link>http://localhost:1313/docsgo/istio/2-releases/</link>
      <pubDate>Tue, 14 May 2024 14:04:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/2-releases/</guid>
      <description>直接进入尽快使用 Istio，但是此篇并不打算太过深入&#xA;环境：MAC、Arm64、minikube&#xA;Istio 实际上是一个不同工具的集合 - 框架，包装在一起，所以在 Istio 中有相当多的组件&#xA;woat is Istio？ Istio 被称为服务网格，在曾经很多面试官都喜欢问我 什么是 Istio ？？？&#xA;可以说 Istio 是一个服务网格 “Service Mesh”，那么意味着需要知道服务网格的概念是什么&#xA;当正在使用基于集群的微服务，会发现作为一个现有的框架，比如 kubernets，就其本身而言并不是相当完美，服务网格也不会取代 kubernetes，它实际上是一个额外的 软件层，和 Kubernetes 一起部署，服务网格不仅仅与 Kubernets 无关，任何一种分布式体系中这就是多个软件组件网格的地方。彼此直接，将从服务网格中受益。所以至今为止，Kubenrets 都被称为：编排框架。&#xA;🤔 一个标准的微服务体系结构在 Kubenrets 中运行&#xA;我们会有：&#xA;一大堆的 Pod，每个Pod包含 一个或多个 Container。但是它是相当标准的，只有一个 Container 使用了服务发现机制，在Kubernets 内部从任何容器进行网络调用。 k8s非常删除去管理Pod，如果需要删除一个Pod，向apiserver发生命令、kubectl、修改yaml等等。&#xA;但是，Kubernets 不擅长管理或在任何情况下管理Pod之间网络，很难推断出里面发生了什么，例如互联网络通信里面有一个错误，网络请求有一些是错误的。虽然可以对软件进行粗略的研究或者分析日志然后推断出出了什么事。&#xA;如果知道是哪个容器出了问题还好，但是如果有数千个微服务，这些网络协调的组合非常复杂。只是标准的 Kubenrets，没有任何互联的不可见性或控制权。 🎯 这就是 服务网格可以提供帮助的地方&#xA;形容词：Service Mesh 【服务网格】&#xA;Istio 如何实施，从概念上以某种方式将通过集群中运行的网络流量将通过本服务网格软件进行路由。&#xA;例子：Pod 至今建立访问，通过 SVC 直接访问&#xA;但是有了 Service Mesh，将设置使所有访问都通过 Service Mesh 进行定向。&#xA;容器实际上不会钓鱼目标容器，它的网络请求是到 Service Mesh，然后Service Mesh 将负责记录指向目标。</description>
    </item>
    <item>
      <title>第1章：Istio 简介</title>
      <link>http://localhost:1313/docsgo/istio/1-introduction/</link>
      <pubDate>Tue, 14 May 2024 14:04:39 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/istio/1-introduction/</guid>
      <description>🚀 Istio将K8s提升到了一个新的高度，那是因为 Istio 提供了一套非常丰富的工具负责监测、管理和保障k8s集群。&#xA;目标：可理解、可使用在生产项目中&#xA;微服务架构非常复杂，Istio 会提供一个 UI视图到Pod级别，看到它们是如何连接在一起的，存在问题的地方，还有分布式追踪，还可以在不进入集群的情况下改变流量。&#xA;例如：将未经过测试的新软件投入到一个生产集群，可以对普通用户隐藏，只有运维工程师将能够访问它。可以做像金丝雀释放一样的事情，可以改进系统的弹性和安全性，增加熔断器。着一直是微服务架构最佳实践，但是传统中很难做，Istio使它变得简单。&#xA;安全 - 整个集群中设置加密&#xA;学习计划安排：&#xA;1 - Introduction 2 - Getting Started 3 - Optional Installing a Local Kubernetes Environment 4 - Hands on Demo 5 - Introducing Envoy 6 - Telemetry 7 - Traffic Management 8 - Load Balancing 9 - Gateways 10 - Dark Releases 11 - Fault Injection 12 - Circuit Breaking 13 - Mutual TLS 14 - Customizing and Installing Istio with Istioctl 15 - Upgrading Istio 16 - Goodbye </description>
    </item>
    <item>
      <title>第19章 安全集群 通过网络策略控制流量</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC19%E7%AB%A0-%E5%AE%89%E5%85%A8%E9%9B%86%E7%BE%A4-%E9%80%9A%E8%BF%87%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5%E6%8E%A7%E5%88%B6%E6%B5%81%E9%87%8F/</link>
      <pubDate>Mon, 13 May 2024 10:01:52 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC19%E7%AB%A0-%E5%AE%89%E5%85%A8%E9%9B%86%E7%BE%A4-%E9%80%9A%E8%BF%87%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5%E6%8E%A7%E5%88%B6%E6%B5%81%E9%87%8F/</guid>
      <description>如果需要进行安全审计，查看存在哪些安全漏洞是可以解决的。&#xA;假设：安全团队发现他们可以入侵前段应用程序Pod，并且获得整个集群的访问权限 如果发生在现实中，这是一个很大的安全问题，但是可以很容易修复。&#xA;当它被攻击时，应用程序之间的所有通信都是被允许的&#xA;隐患：对于部件或服务可以相互通信没有限制 网络策略组件：定义了集群中谁可以访问谁&#xA;定义在本地 不是所有的 CNI插件都支持，常用的CNI插件&#xA;Calico Cilium 严格的集群间通信规则会使得集群更加安全。&#xA;参考：https://kubernetes.io/zh-cn/docs/concepts/services-networking/network-policies/&#xA;两个规则：&#xA;Ingress Egress NetworkPolicy 的示例：&#xA;apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: test-network-policy namespace: default spec: podSelector: matchLabels: role: db policyTypes: - Ingress - Egress ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 egress: - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 </description>
    </item>
    <item>
      <title>第18章: Kubernetes 中的证书管理</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC18%E7%AB%A0-kubernetes%E4%B8%AD%E7%9A%84%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</link>
      <pubDate>Sat, 11 May 2024 15:56:21 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC18%E7%AB%A0-kubernetes%E4%B8%AD%E7%9A%84%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</guid>
      <description>集群证书续期 集群已经运行了半年多，一个成员突然提出&#xA;应该检查证书何时到期，并在需要的时候续订 检查1：&#xA;openssl 命令来读取证书的到期时间&#xA;openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -enddate openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout 检查2：&#xA;生成新的密钥 - 使用 kubeadm 将会非常简单 kubeadm certs --helm kubeadm certs check-expiration 证书默认1年&#xA;更新：&#xA;openssl 生成新的证书和私钥 或者 使用 kubeadm 更新证书注意：&#xA;更新集群，kubeadm 会自动续订证书 为 kubelet 配置证书轮换 https://kubernetes.io/zh-cn/docs/tasks/tls/certificate-rotation/&#xA;Kubelet 使用证书进行 Kubernetes API 的认证。 默认情况下，这些证书的签发期限为一年，所以不需要太频繁地进行更新。&#xA;Kubernetes v1.8 和更高版本的 kubelet 实现了对客户端证书与/或服务证书进行轮换这一特性。 请注意，服务证书轮换是一项 Beta 特性，需要 kubelet 上 RotateKubeletServerCertificate 特性的支持（默认启用）。</description>
    </item>
    <item>
      <title>第7章:  Kubernetes中的高级调度</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC7%E7%AB%A0-kubernetes%E4%B8%AD%E7%9A%84%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6/</link>
      <pubDate>Sun, 05 May 2024 23:25:04 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC7%E7%AB%A0-kubernetes%E4%B8%AD%E7%9A%84%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6/</guid>
      <description>kubernetes 最大优势就是可以抽象出单独的服务器，不需要担心各个服务器细节。&#xA;内置调度器：决定将工作负载放在哪里，例如想调度一个Pod&#xA;先过滤掉不符合条件的节点，剩余的节点成为：可调度节点 运行一组函数对节点进行打分，然后会选最高分的节点来运行【如果是多个相同最高分节点，随机选】这个过程称为绑定 实际的生产环境中可能有不同的节点，高CPU、高内存、高性能存储、GPU、云上按需计费、包年&amp;hellip;,性能差异的节点等等&#xA;nodeName 直接将 Pod 固定在一个节点上&#xA;apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeName: node1 Kubernetes Node Selector 将 nodeSelector 字段添加到 Pod 的规约中，Kubernetes 只会将 Pod 调度到拥有你所指定的每个标签的节点上。&#xA;缺点：不灵活&#xA;可以使用：亲和性和反亲和性扩展了你可以定义的约束类型 kubectl get node --show-labels 可以为特定节点上分配特定标签，也有一些默认的标签&#xA;[root@local ~]# kubectl get node --show-labels NAME STATUS ROLES AGE VERSION LABELS monitor Ready control-plane,master 11d v1.29.3+k3s1 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=k3s,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=monitor,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=true,node-role.kubernetes.io/master=true,node.kubernetes.io/instance-type=k3s 添加标签：&#xA;kubectl label nodes &amp;lt;your-node-name&amp;gt; disktype=ssd Pod</description>
    </item>
    <item>
      <title>第6章: 使用用户和权限控制访问</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC6%E7%AB%A0-%E4%BD%BF%E7%94%A8%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%E8%AE%BF%E9%97%AE/</link>
      <pubDate>Sat, 04 May 2024 22:10:20 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC6%E7%AB%A0-%E4%BD%BF%E7%94%A8%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%E8%AE%BF%E9%97%AE/</guid>
      <description>1 - 章节简介 权限：&#xA;谁可以访问？【并不是每个人都是管理员】 访问什么资源？做什么事情？ 授用户或应用程序的四种方法：&#xA;Node：节点鉴权是一种特殊用途的鉴权模式，专门对 kubelet 发出的 API 请求进行授权。 ABAC：基于属性的访问控制（Attribute-based access control，ABAC）定义了访问控制范例， ABAC 通过使用将属性组合在一起的策略来向用户授予访问权限。 RBAC：基于角色（Role）的访问控制（RBAC）是一种基于组织中用户的角色来调节控制对计算机或网络资源的访问的方法。 WebHook：具体来说，当在判断用户权限时，Webhook 模式会使 Kubernetes 查询外部的 REST 服务。 但是，我们实际上只需要了解RBAC&#xA;在 apiserver配置中，--authorization-mode=Node,RBAC&#xA;2-将用户和权限与 RBAC 角色解耦 当在CMD使用 kubectl 执行命令时，会发生：&#xA;kubectl 读取本地的 kubeconfig 配置 将访问kubenetes api server，并发现API 【着仅仅是检查API可用性】 kubectl 将执行客户端验证【检查 yml 中是否有错误】 将数据发送给 api server 请求，收到请求并不会直接存储在 etcd 中 首先，验证请求是否合法【对请求做身份验证 - 是否有权限创建这些资源】，有权限访问集群并不意味着有权限创建、读取、删除等等 【通常通过 RBAC来控制，精细的控制权限】 如果未授权，则返回401，否则进入下一步 3 - Kubernetes RBAC ==RBAC：意在根据个人角色授权对资源的访问==&#xA;从头开始设计授权系统&#xA;为权限定义一个通用的 role 将权限分配给role，而不是直接向用户分配权限 将 role 链接到 用户 RBAC：</description>
    </item>
    <item>
      <title>第5章：Ingress</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC5%E7%AB%A0-ingress/</link>
      <pubDate>Sat, 04 May 2024 15:40:14 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC5%E7%AB%A0-ingress/</guid>
      <description>官方文档&#xA;简述 Ingress 提供从集群外部到集群内服务的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源所定义的规则来控制。&#xA;使用LB存在的缺点：&#xA;如果需要包括多个服务，将会得到一组 LB，我们想让用户访问：通过域名，而非LB的域名或者IP。没有一个域名可以让我们访问所有LB服务 在服务器上将会使 NodePort 暴露多个端口。 Ingress：集群入口组件，接受请求并路由到服务&#xA;部署在集群内，将ingress svc 端口暴露出去。【所以我们将只需要一个LB】 Ingress 不会随意公开端口或协议。 将 HTTP 和 HTTPS 以外的服务开放到 Internet 时，通常使用 Service.Type=NodePort 或 Service.Type=LoadBalancer 类型的 Service。 Ingress语法：&#xA;apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: minimal-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: ingressClassName: nginx-example rules: - http: paths: - path: /testpath pathType: Prefix backend: service: name: test port: number: 80 https：&#xA;apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: tls-example-ingress spec: tls: - hosts: - https-example.</description>
    </item>
    <item>
      <title>05 云安全AWS</title>
      <link>http://localhost:1313/docsgo/devsecops/05-%E4%BA%91%E5%AE%89%E5%85%A8aws/</link>
      <pubDate>Fri, 03 May 2024 10:56:31 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/05-%E4%BA%91%E5%AE%89%E5%85%A8aws/</guid>
      <description>云安全 (AWS)&#xA;AWS 访问管理（用户、组、角色、策略） AWS安全 IaC AWS日志记录和监控 AWS 访问管理 安全最佳实践：最低访问权限&#xA;云平台也需要确保网络安全：AWS 账户安全&#xA;谁可以获得什么服务 或者用户和权限 如果有人错误的访问 AWS 资源，那就存在安全风险，管理不到位。&#xA;可能会导致 窃取凭据和对账户的访问，以至于可以再环境中为所欲为。&#xA;​&#x9;也许你的VPC网络超级安全，而且没人能从网上进入你的网络，但是如果允许对于许多员工有高权限，忘记撤销，比如前员工，或者只是管理管道中的代码凭证，然后有人窃取这些凭证直接访问资源。&#xA;​&#x9;更本不需要费力去入侵网络，只需要登陆你的账户访问&#xA;配置管理用户权限&#xA;每个项目，每个存储库，都可以是一个单独的角色&#xA;网络配置 权限管理 部署到AWS AWS ECR服 AWS 访问管理本身非常重要！！【最低访问权限】&#xA;用户、权限、策略、的创建和管理 一旦不需要访问某个资源，或者项目结束，或者是换了团队。&#xA;监视用户操作：&#xA;也许是因为没有足够的知识 也许是故意的 用户、组、角色&#xA;保护AWS账户：&#xA;IAM 服务 对AWS的所有访问都收到管理： IAM 服务&#xA;root 用户，管理aws 所有，可以做任何事情&#xA;MFA 多因子认证 不要轻易使用 生成root 的认证凭证 如果我们需要为cicd 管道创建一个连接的凭证：&#xA;我们不能给所有人 root 权限，尤其是管道和各种工具，事实上没人应该使用它。&#xA;有些事情只能 root 去做：访问账单、支付信息、更新账户等等&#xA;创建一个 admin user&#xA;再通过 admin 创建其他用户，包括管道用户。&#xA;假设团队中：开发、测试、运维、网络管理员&#xA;访问方式：UI、凭证 gitlab 不需要 Ui登陆AWS，所以只需要创建一个 专有凭证的用户</description>
    </item>
    <item>
      <title>第6章：构建安全镜像</title>
      <link>http://localhost:1313/docsgo/devsecops/04-%E6%9E%84%E5%BB%BA%E5%AE%89%E5%85%A8%E9%95%9C%E5%83%8F/</link>
      <pubDate>Wed, 01 May 2024 18:57:11 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/04-%E6%9E%84%E5%BB%BA%E5%AE%89%E5%85%A8%E9%95%9C%E5%83%8F/</guid>
      <description>docker 镜像安全&#xA;容器镜像由层和软件包组成，容易受到漏洞的影响。这些漏洞可能会危及容器和应用程序的安全。&#xA;存在问题的 dockerfile&#xA;FROM node:18 as installer COPY . /juice-shop WORKDIR /juice-shop RUN npm i -g typescript ts-node RUN npm install --omit=dev --unsafe-perm RUN npm dedupe RUN rm -rf frontend/node_modules RUN rm -rf frontend/.angular RUN rm -rf frontend/src/assets RUN mkdir logs RUN chown -R 65532 logs RUN chgrp -R 0 ftp/ frontend/dist/ logs/ data/ i18n/ RUN chmod -R g=u ftp/ frontend/dist/ logs/ data/ i18n/ RUN rm data/chatbot/botDefaultTrainingData.json || true RUN rm ftp/legal.</description>
    </item>
    <item>
      <title>第4章: External_Services</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC4%E7%AB%A0-external_services-ingress/</link>
      <pubDate>Tue, 30 Apr 2024 10:41:13 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC4%E7%AB%A0-external_services-ingress/</guid>
      <description>详细官方文档：【https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/#publishing-services-service-types】&#xA;SVC 服务的IP从何来？&#xA;SVC的IP和PodIP在完全不同的范围&#xA;如果更新了 svc的 CIDR，旧的分配的IP将会保留&#xA;默认service 类型： ClusterIP&#xA;创建：&#xA;[root@local ~]# kubectl create service clusterip test-new-cidr --tcp=80:80 --dry-run=client -o yaml apiVersion: v1 kind: Service metadata: creationTimestamp: null labels: app: test-new-cidr name: test-new-cidr spec: ports: - name: 80-80 port: 80 protocol: TCP targetPort: 80 selector: app: test-new-cidr type: ClusterIP deployment 同样：&#xA;[root@local ~]# kubectl create deployment my-nginx -n default --image=nginx --dry-run=client -o yaml Service Service API 是 Kubernetes 的组成部分，它是一种抽象，帮助你将 Pod 集合在网络上公开出去。 每个 Service 对象定义端点的一个逻辑集合（通常这些端点就是 Pod）以及如何访问到这些 Pod 的策略。</description>
    </item>
    <item>
      <title>Kubernetes DNS</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/kubernetes-dns/</link>
      <pubDate>Sun, 28 Apr 2024 17:36:34 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/kubernetes-dns/</guid>
      <description>CoreDNS 深入探讨&#xA;好文：https://pracucci.com/kubernetes-dns-resolution-ndots-options-and-why-it-may-affect-application-performances.html&#xA;CoreDNS 最著名的是云原生生态系统中 Kubernetes 的默认集群 DNS，它也是一个可扩展且灵活的 DNS 服务器，专注于服务发现。 CoreDNS 的可扩展性来自其独特的基于插件的架构，可以轻松添加新功能。&#xA;在k8s这种Pod IP 会发生变化的集群中，使用IP访问是很糟糕的&#xA;DNS：IP翻译成域名&#xA;文件：&#xA;/etc/hosts /etc/resolv.conf 当集群中存在数百个服务，这将是大量的&#xA;/etc/resolv.conf中&#xA;nameserver 10.233.0.3 为 DNS服务器&#xA;1.12版本前使用kube-dns，之后使用 CoreDNS&#xA;[root@local ~]# kubectl get pod -A --show-labels NAMESPACE NAME READY STATUS RESTARTS AGE LABELS kube-system coredns-6799fbcd5-c869r 1/1 Running 0 47m k8s-app=kube-dns,pod-template-hash=6799fbcd5 Pod内：&#xA;[root@local ~]# kubectl exec -ti nginx-7854ff8877-5dtzt -- sh # cat /etc/hosts # Kubernetes-managed hosts file. 127.0.0.1&#x9;localhost ::1&#x9;localhost ip6-localhost ip6-loopback fe00::0&#x9;ip6-localnet fe00::0&#x9;ip6-mcastprefix fe00::1&#x9;ip6-allnodes fe00::2&#x9;ip6-allrouters 10.</description>
    </item>
    <item>
      <title>第5章：构建安全CI</title>
      <link>http://localhost:1313/docsgo/devsecops/03-%E6%9E%84%E5%BB%BA%E5%AE%89%E5%85%A8ci/</link>
      <pubDate>Sun, 28 Apr 2024 15:42:54 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/03-%E6%9E%84%E5%BB%BA%E5%AE%89%E5%85%A8ci/</guid>
      <description>简述 从一个项目开始：https://gitlab.com/baimiyishu13/juice-shop&#xA;可以完美展示应用程序代码和配置中的安全问题。&#xA;不需要理解 99% 代码，只是使用 创建管道文件：gitlab-ci.yml&#xA;docker 镜像：https://hub.docker.com/_/docker&#xA;使用，无需使用 shell 去安装docker 构建&#xA;image: docker:26 services: - docker:26-dind 先构建服务镜像：&#xA;--- stages: - test - build variables: GIT_DEPTH: 0 IMAGE_NAME: $CI_REGISTRY_IMAGE/demo-app IMAGE_TAG: juice-shop-1.1 yarn_test: image: node:18-alpine3.18 script: - yarn install - yarn test build_image: stage: build image: docker:26 services: - docker:26-dind before_script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY script: - docker build -t $IMAGE_NAME:$IMAGE_TAG . - docker push $IMAGE_NAME:$IMAGE_TAG 使用的共享 runner ，差不多花费了 15min，来执行这两项任务。</description>
    </item>
    <item>
      <title>01 Efk</title>
      <link>http://localhost:1313/docsgo/efk/01-efk/</link>
      <pubDate>Sun, 28 Apr 2024 11:08:02 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/efk/01-efk/</guid>
      <description>在集群内使用EFK堆栈&#xA;HELM 安装&#xA;实验：将创建2个 程序进行测试&#xA;地址：https://gitlab.com/baimiyishu13/node-app&#xA;➜ node-app git:(master) ls Dockerfile app node_modules package.json Readme.md deployment.yaml package-lock.json 构建测试镜像：&#xA;docker build -t node-app . docker tag node-app demo-app:node-1.0 ➜ node-app git:(master) docker images | grep node-1.0 demo-app node-1.0 1e9ad3a8910c 13 seconds ago 117MB 第二个程序&#xA;docker build -t java-app . docker tag java-app demo-app:java-1.0 部署前须知概念 ElasticSearch：&#xA;将部署多副本的有状态ElasticSearch程序 简述： 用于搜索和分析的数据存储，可以存储许多不同的形式，例如SQL数据库，仅以结构化形式存储数据 表/行/列。&#xA;ElasticSearch 可以存储费结构化数据，着意味着无需任何域定义的形式&#xA;主要优势：强大的搜索机制</description>
    </item>
    <item>
      <title>第1章 Kubernetes核心概念</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC1%E7%AB%A0-kubernetes%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Fri, 26 Apr 2024 22:44:23 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/%E7%AC%AC1%E7%AB%A0-kubernetes%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</guid>
      <description>重新学习Kubernetes ，弥补遗漏知识。&#xA;常用组件：Pod、service、ingress、configmap、secret、volume、deployment、statefulset、daemonset&#xA;容器编排 容器编排工具的任务？&#xA;从时间顺序上该问题：&#xA;微服务的兴起导致了容器技术使用的增加，容器技术提供了一个完美的主机 在都个主机环境使用脚本或者自制的工具管理会非常麻烦，这种情况下出现了对容器编排的需求。 所以kubernetes 所做的就是&#xA;高可用性：高可用意味着：程序没有停机时间，总是可以让用户访问 扩展性：快速扩展程序 【动态调整负载】 灾难恢复，基础设施出现问题、数据丢失、服务器崩溃等，应用程序不会丢失任何数据。 核心组件 每个节点&#xA;container runtime kubelet kube-proxy：service本身就是LB，捕捉请求指向应用程序 master：&#xA;api server Pod Pod：抽象概念，Pod的作用基本是就是创建容器运行的环境。或在容器上面的一个层。&#xA;Pod之间通信：&#xA;k8s 的CNI 提供了 虚拟网络，每个Pod都会有一个IP。 这个IP是会变化的。【容器奔溃重启等等原因】会分配一个新的IP。 Service service：一个静态的IP或永久的地址，可以连接到每个通过标签匹配到的Pod。&#xA;好处：service 和 Pod的生命周期不相互连接。【即使Pod死亡，Service 和 它的IP也会保持不变】&#xA;显然接下来希望应用程序通过外部访问&#xA;Ingress 代替 NodePort&#xA;Volume 外部配置：configmap&#xA;加密配置：secret，使用base64，实际上并不能加密，所以会使用第三方工具。&#xA;如果希望数据或日志数据可靠的存储下来，可以做啊都这件事的组件：Volume&#xA;存储：可以是节点磁盘，也可以是远程存储 。&#xA;工作负载 deployment&#xA;statefulset：部署数据库、有状态服务&#xA;使用有状态部署数据库在k8s集群，会有性能等问题，所以使用集群外托管数据库是一种常见的做法。 demonset：每个节点部署一个Pod，负责代理、日志收集、守护进程等。</description>
    </item>
    <item>
      <title>第一章：Argocd-Kubernetes的GitOpsCD</title>
      <link>http://localhost:1313/docsgo/argocd/01-argocd%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Fri, 26 Apr 2024 14:32:59 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/argocd/01-argocd%E5%9F%BA%E7%A1%80/</guid>
      <description>1-简述 ArgoCD 是一种 GitOps 持续交付工具，在 DevOps 中越来越受欢迎。&#xA;官网：https://argo-cd.readthedocs.io/en/stable/&#xA;学习前必备知识：&#xA;docker 、kubernetes、HELM(可选)、CICD工具其一即可（gitlab、github、jenkins） Argo CD : 持续交付工具，将Argocd理解成CD工具或持续交付的工具，对比实验 Jenkins 或者 gitlab 中的持续交付。&#xA;所以，Argocd 并不存在取代 jenkins 或者 gitlab等等说法&#xA;设计实验仓库：&#xA;https://gitlab.com/mymicroservice-cicd9154417&#xA;1-1 不使用 ArgoCD 的 CD 工作流程 假设我们有一套服务运行在 k8s集群。&#xA;当我们新增功能或者代码发生改变时，使用 jenkins 或者 gitlab 构建的 ci 管道构建了新的镜像，并将其推送到仓库，此时这个镜像如何部署？&#xA;使用 yml 更新镜像tag，部署到集群，这些操作是 CI 管道的延续 因此 jenkins 或 gitlab 将更新应用程序的部署 yml，并使用 kubectl 去更新部署 这种方法存在的挑战：&#xA;需要设置安装kubectl 或者 helm等工具来访问集群 还需要为这些工具配置访问，连接凭据 【如果使用的是云集群，还需要配置 ak、sk等等】 引出的问题：配置工作量、安全问题【将集群凭证和 云凭证提供给了外部服务】&#xA;另一个问题：&#xA;使用管道部署后，无法进一步了解应用程序状态。管道并不知道执行 更新后负载的状态 【即使可以通过脚本去实现，但将会使管道冗余和加长管道执行时间】 1-2 使用 ArgoCD 的 CD 工作流程 Argo CD 结合 Gitlab 将更加高效，可以持续交付的 kubernetes。</description>
    </item>
    <item>
      <title>第8章: 部署到Kubernetes集群</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/07-%E9%83%A8%E7%BD%B2%E5%88%B0kubernetes%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Fri, 26 Apr 2024 11:03:38 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/07-%E9%83%A8%E7%BD%B2%E5%88%B0kubernetes%E9%9B%86%E7%BE%A4/</guid>
      <description>准备k8s集群&#xA;部署到集群需要：kube-config&#xA;shell runner 上安装 kubectl 命令 【https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/】 不应该给 gitlab 直接访问集群的权限，如果 gitlab 被攻破，集群也会&#xA;为gitlab创建一个单独的 sa，赋予特定权限 gitlab-kubeconfig kubectl create namespace my-micro-service kubectl create sa icd-sa -n my-micro-service vi cicd-role.yml # 配置role kubectl create rolebinding cicd-rb --role=cicd-role --serviceaccount=cicd-sa -n my-micro-service deploy-k8s.yml&#xA;deploy: stage: deploy before_script: - export IMAGE_NAME=$CI_REGISTRY_IMAGE/microservice/$MICRO_SERVICE - export IMAGE_TAG=$SERVICE_VERSION - export MICRO_SERVICE=$MICRO_SERVICE - export SERVICE_PORT=$SERVICE_PORT - export REPLICAS=$REPLICAS - export KUBECONFIG=$KUBE_CONFIG script: - kubectl create secret docker-registry my-registry-key --docker-server=$CI_REGISTRY --docker-username=$GITLAB_USER --docker-password=$GITLAB_PASSWORD -n my-micro-service --dry-run=client -o yaml | kubectl apply -f - - envsubst &amp;lt; kubernetes/deployment.</description>
    </item>
    <item>
      <title>第7章: 部署微服务应用程序（Mono 和 Polyrepo）</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/07-%E9%83%A8%E7%BD%B2%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Thu, 25 Apr 2024 10:35:41 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/07-%E9%83%A8%E7%BD%B2%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/</guid>
      <description>为微服务配置管道。&#xA;生产环境：很多 CICD 管道都是微服务相关 多微服务-单存储库：常见方法，使用文件夹&#xA;多微服务-多存储库 - group 组&#xA;共享的 runner、变量 每个存储库都有自己的 cicd 实验：&#xA;多微服务-单存储库 应用：3个服务【ui、shopping-cart 、products】&#xA;项目：https://gitlab.com/baimiyishu13/mymicroservice-cicd&#xA;在CICD设置中启用 runner 【当Runner被锁定时，不能将其分配给其他项目 勾选为空时 可共享操作】\&#xA;关键配置：&#xA;build_frontend: extends: .build variables: MICRO_SERVICE: frontend SERVICE_VERSION: &amp;#34;1.3&amp;#34; only: changes: - &amp;#34;frontend/**/*&amp;#34; 解读：只有当frontend 目录下文件改变时，才会触发流水线&#xA;/**/* 会匹配 frontend 目录及其所有子目录下的所有文件。 如果仅修改了frontend 目录下的文件，即，只变更frontend 微服务&#xA;--- workflow: rules: - if: $CI_COMMIT_BRANCH != &amp;#34;main&amp;#34; &amp;amp;&amp;amp; $CI_PIPELINE_SOURCE != &amp;#34;merge_request_event&amp;#34; when: never - when: always variables: GIT_DEPTH: 0 DEPLOYMENT_SERVER_HOST: &amp;#34;1.15.176.240&amp;#34; APP_ENDPOINT: http://$DEPLOYMENT_SERVER_HOST:3001 stages: - build - deploy .</description>
    </item>
    <item>
      <title>第6章：高级管道：版本控制、缓存、多阶段……</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/06-%E9%AB%98%E7%BA%A7%E7%AE%A1%E9%81%93/</link>
      <pubDate>Wed, 24 Apr 2024 14:30:19 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/06-%E9%AB%98%E7%BA%A7%E7%AE%A1%E9%81%93/</guid>
      <description>版本控制 当前我们构建的文件中，镜像版本&#xA;variables: GIT_DEPTH: 0 IMAGE_NAME: $CI_REGISTRY_IMAGE IMAGE_TAG: &amp;#34;1.2&amp;#34; APP_PORT: 3001 如果不增加修改，将会一直是1.2，这样做不现实因为会产生覆盖。&#xA;生产环境中，每次管道构建都会产生一个新的版本&#xA;随着程序改进，我们依然希望保留跟踪版本直接的变化 设置递增版本过程 版本 1.1.1&#xA;第一个数字： 程序重大改动，重构，替换编码框架 第二个数字：次要更改，新功能，大的bug修复 第三个数字：补丁版本，小的修改，例如较小的bug修复 在 CI 文件中读取程序的 版本&#xA;服务器安装 jq 命令 [root@monitor ~]# cat p.json | jq -r &amp;#39;.version&amp;#39; 1.0.0 build_image: stage: build tags: - ec2 - aws - shell before_script: - export APP_VERSION=$(cat app/package.json | jq -r &amp;#39;.version&amp;#39;) script: - docker build -t $IMAGE_NAME:$APP_VERSION . 即使这样，还需每次修改应用程序中的 version&#xA;在构建镜像是 为 Image 添加 TAG 【预定义变量】</description>
    </item>
    <item>
      <title>第5章：生产环境中的管道</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/05-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E7%AE%A1%E9%81%93/</link>
      <pubDate>Tue, 23 Apr 2024 15:42:55 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/05-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E7%AE%A1%E9%81%93/</guid>
      <description>将构建打包应用程序，构建镜像打包部署到环境&#xA;使用项目：https://gitlab.com/baimiyishu13/mynodeapp-cicd-project，构建一个完整的 cicd 管道&#xA;具体有以下步骤：&#xA;单元测试 STAT 应用程序安全测试，扫描代码安全 docker build docker push Registry deploy -DEV deploy -test deploy-生产 第一步：单元测试 --- workflow: rules: - if: $CI_COMMIT_BRANCH != &amp;#34;main&amp;#34; &amp;amp;&amp;amp; $CI_PIPELINE_SOURCE != &amp;#34;merge_request_event&amp;#34; when: never - when: always run_unit_test: image: node:21-alpine tags: - ec2 - aws - docker before_script: - cd app - npm install script: - npm test artifacts: when: always paths: - app/junit.xml reports: junit: app/junit.xml 解释：&#xA;artifacts 关键字用于指定在 job 运行后需要保存的文件或目录 path: app/junit.</description>
    </item>
    <item>
      <title>第4章：GitLab架构: Runners, 执行器</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/04-gitlab-%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Mon, 22 Apr 2024 16:47:48 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/04-gitlab-%E6%9E%B6%E6%9E%84/</guid>
      <description>GItLab 架构 触发的管道&#xA;问题：gitlab 在哪里执行这些操作，就想执行的echo、ls、创建文件等等，实际上发生在哪里。&#xA;必须在某个服务器或者环境中运行&#xA;gitlab.com 本身托管的gitlab 实例 gitlab runner：安装在单独服务器，而不是运行在gitlab 服务器上，连接到gitlab服务器就可以执行gitlab服务器发给它的job。所谓的运行器【可供所有用户使用】 执行器 选择那种类型的执行器：&#xA;每个都有自己的用例&#xA;一般使用linux 构建标准的 ci cd 管道 docker 执行器 kubernetes 集群中执行 定义和配置 gitlab runner 执行器&#xA;可以在一台服务器运行多个执行器&#xA;Shell 执行器 gitlab runner 实际上就是一个中介，它将从 gitlab 获取到的作业命令移交给它正在运行的服务器的 shell，实际上是在 gitlab runner 运行的服务器。&#xA;执行作业的服务器，通常也称为：shell 执行器&#xA;意味着需要使用命令：&#xA;docker go npm maven 等等，都需要安装这些工具，升级版本等等。意味着需要管理员大量的操作&#xA;Docker 执行器 可以随意安装服务、工具，不必在服务端配置其他。&#xA;每个job 都会在干净环境中启动&#xA;VM 执行器 每个作业都需要加载一个 vm 整个操作系统，意味着会非常慢&#xA;Kubernetes 执行器 意味着现在有一个集群，将创建一个新的Kubernetes Pod 作为运行环境&#xA;Docker Machine 执行器 docker 的扩展&#xA;创建docker主机，在一台机器上管理多个Docker 实例</description>
    </item>
    <item>
      <title>第3章：Gitlab CICD核心概念 作业、阶段、变量...</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/03-gitlab-cicd%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Sun, 21 Apr 2024 17:46:46 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/03-gitlab-cicd%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</guid>
      <description>gitlab-ci.yml&#xA;Jobs Job: 管道中的一个步骤或执行某个操作的工作流&#xA;script: 执行如何命令、Linux 命令 before_scrip: 安装依赖项、设置环境变量等 after_script: 通常用于清理作业环境，例如删除临时文件、停止服务等 pipeine&#xA;--- run_tests: before_script: - echo &amp;#34;Setting up test environment&amp;#34; - apk add yamllint script: - echo &amp;#34;Running tests&amp;#34; - yamllint gitlab-ci.yml after_script: - echo &amp;#34;Cleaning up test environment&amp;#34; build_image: script: - echo &amp;#34;Building image&amp;#34; - docker build -t node_exporter . push_image: script: - echo &amp;#34;Pushing image&amp;#34; - docker push node_exporter 实验项目：https://gitlab.com/baimiyishu13/mynodeapp-cicd-project&#xA;创建：.gitlab-ci.yml 会自动识别为管道文件&#xA;stage &amp;amp; stages 如果不想入上并行，则使用 stage</description>
    </item>
    <item>
      <title>第2章：CI/CD和GitLab比较</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/02-cicd%E5%92%8Cgitlab%E7%9A%84%E6%AF%94%E8%BE%83/</link>
      <pubDate>Sun, 21 Apr 2024 17:15:34 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/02-cicd%E5%92%8Cgitlab%E7%9A%84%E6%AF%94%E8%BE%83/</guid>
      <description>gitlab cicd 不是唯一的 cicd 工具&#xA;Jenkins vs gitlab&#xA;Jenkins：&#xA;仍然非常强大，集成了各种技术 很大插件、灵活 但是：Jenkins 已经存在了很长时间，实际上并不是那么先进 jenkins 只是一个 cicd 工具 Jnekins 安装在自己的服务器，自己管理一切 GitLab：&#xA;保持与时俱进 构建功能齐全的 devops 平台 非常符合行业发展的软件 提供了很大开箱即用的工具、用于测试、存储、部署 gitlab 托管存储库，从存储库中构建 Jenkins 不仅可以托管，还可以在自己服务器上部署 </description>
    </item>
    <item>
      <title>第1章：概述</title>
      <link>http://localhost:1313/docsgo/cicd/gitlab/01-%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Sat, 20 Apr 2024 21:03:14 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/cicd/gitlab/01-%E4%BB%8B%E7%BB%8D/</guid>
      <description>构建持续集成管道&#xA;使用实际的最佳的方式 做正确的事情&#xA;GitLab CI/CD 就是一个cicd平台&#xA;CI/CD 定义：【what is cicd】 CI/CD 平台可以做什么 Devops：&#xA;公司有一个应用程序，需要对其 编码、测试，有测试程序，构建打包，最后部署到服务器&#xA;每次改进程序、代码等，都可以让用户快速体验改改进。&#xA;每次更新：版本控制 这样就有了一个持续交付的变更&#xA;一个无休止的循环 cicd 这是 devops 过程的核心，是一个自动化方式频繁向客户交付应用程序更改的方法&#xA;CI、CD的实际含义：&#xA;CD：应用程序构建后部署到环境，但为了避免更改导致程序奔溃，即使是小的代码改动，所以发布前需要：&#xA;开发部署的第一阶段：Dev环境，与生产环境相似。 测试：【运行自动化测试（如单元测试、功能测试）】、分析代码测试 预生产环境：验证所有功能、性能测试 生产环境：最终部署阶段 整个阶段：会有人为干预，比如手动测试、审批等&#xA;CI：当开发人员将代码提交触发管道</description>
    </item>
    <item>
      <title>第4章：应用程序漏洞扫描</title>
      <link>http://localhost:1313/docsgo/devsecops/3-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/</link>
      <pubDate>Fri, 19 Apr 2024 23:31:03 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/3-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/</guid>
      <description></description>
    </item>
    <item>
      <title>第3章：DevSecOps简介</title>
      <link>http://localhost:1313/docsgo/devsecops/2-devsecops%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Fri, 19 Apr 2024 17:32:38 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/2-devsecops%E7%AE%80%E4%BB%8B/</guid>
      <description>以前的Devops 安全 和 DevSecOps&#xA;以前：&#xA;开发 - 自动化测试 - build - deploy 测试环境 - deploy 生产环境 在部署到生产环境之前，安全人员必须做一些事情，如果开发使用了新的库存在漏洞，数据泄漏，镜像安全问题，kubernetes 配置文件出错。&#xA;安全测试小组会测试 并分析变化，可能会发现很多问题、漏洞反馈给开发去新版本修复。 安全审计时间过长又会导致发布新版本受阻，造成应用程序发布周期瓶颈 应用越多意味着更多的攻击面&#xA;加快devops 安全，安全向左&#xA;应用发布之前解决安全问题，从一开始就考虑安全问题 安全性也是开发人员的责任。安全工具将被整合到CICD管道中，识别安全问题，在特定分支中修复更有效。&#xA;反馈周期短，开发能够快速知道问题，并去解决 DevSecOps 是一个架构师，有助于应用程序团队将这些自助检查集成到管道中，确保完成必要的检查，当发现问题时采取行动。&#xA;但是，不是真正解决问题的人，比如不要去修复代码安全问题，做任何更改，这不是DevOpsSec的职责 安全工程师有更专业方向的安全知识</description>
    </item>
    <item>
      <title>第2章： 安全要点</title>
      <link>http://localhost:1313/docsgo/devsecops/1-%E5%AE%89%E5%85%A8%E8%A6%81%E7%82%B9/</link>
      <pubDate>Fri, 19 Apr 2024 16:23:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/1-%E5%AE%89%E5%85%A8%E8%A6%81%E7%82%B9/</guid>
      <description>安全性简介 安全是个很大的话题，每一种几乎都可以成为一个岗位/行业&#xA;应用程序安全 - 软件工程安全 基础设施安全 云 安全 kubernetes 安全 等，几乎都可以是一个单独的项目。&#xA;安全的重要性和安全漏洞的影响：&#xA;安全：线上安全、线下安全都是黑客的切入点。对公司造成伤害。&#xA;如何保护系统免受攻击：不同层次&#xA;安全攻击类型：&#xA;钓鱼攻击，切入点是欺骗，电子邮件链接、下载病毒文件等 应用程序漏洞，开发在编写代码时不够安全 </description>
    </item>
    <item>
      <title>0.认识Kubernetes</title>
      <link>http://localhost:1313/docsgo/kubernetes/study/0-%E8%AE%A4%E8%AF%86kubernetes/</link>
      <pubDate>Fri, 19 Apr 2024 14:12:12 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/study/0-%E8%AE%A4%E8%AF%86kubernetes/</guid>
      <description>Docker 可以使用 docker run 运行简单的应用程序的单个实例，用户数量请求增大时，需要去启动更多的实例。&#xA;需要密切关注应用程序 负载和性能 不仅仅是这些，还有：&#xA;容器故障恢复 主机崩溃等 容器编排是一种解决方案，帮助在生产环节中托管容器</description>
    </item>
    <item>
      <title>Ansible 分子测试</title>
      <link>http://localhost:1313/docsgo/ansible/study/ansible-%E5%88%86%E5%AD%90%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Wed, 17 Apr 2024 22:03:44 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/ansible-%E5%88%86%E5%AD%90%E6%B5%8B%E8%AF%95/</guid>
      <description>Ansible Molecule 是一个用于 Ansible 角色的测试框架。它可以帮助我们创建、运行和测试 Ansible Playbooks。Molecule 提供了一种创建和管理虚拟机的方法，这些虚拟机可以用于测试 Ansible Playbooks。它还提供了一种方法来验证 Playbooks 的行为，这是通过运行一系列的测试来完成的。&#xA;结合 GitHub 使用 Ansible Molecule 的好处包括：&#xA;版本控制：GitHub 提供了一个平台，可以跟踪和管理 Ansible Playbooks 的版本。这意味着你可以轻松地回滚到以前的版本，或者查看 Playbook 的历史记录。 协作：GitHub 允许多个开发者同时在同一个项目上工作。这意味着你可以与团队成员共享和协作 Ansible Playbooks，而不必担心版本冲突。 持续集成/持续部署（CI/CD）：GitHub Actions 可以自动运行 Molecule 测试，每当你提交新的代码到 GitHub 时，它都会自动运行测试。这可以确保你的 Ansible Playbooks 总是按预期工作。 代码审查：GitHub 提供了代码审查工具，这可以帮助你确保 Ansible Playbooks 的质量。你可以在合并代码之前，要求其他开发者审查你的代码。 文档：GitHub 提供了一个平台，可以编写和存储 Ansible Playbooks 的文档。这可以帮助你和你的团队更好地理解和使用 Playbooks。 分子测试文件：node-exporter为例&#xA;converge.yml&#xA;--- - name: Converge hosts: all become: true pre_tasks: - name: Update yum cache. yum: update_cache: yes when: ansible_os_family == &amp;#39;RedHat&amp;#39; changed_when: false roles: - role: node-exporter molecule.</description>
    </item>
    <item>
      <title>Ansible Tower_AWX</title>
      <link>http://localhost:1313/docsgo/ansible/study/tower_awx/</link>
      <pubDate>Tue, 16 Apr 2024 19:40:55 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/tower_awx/</guid>
      <description>tower 或 AWX 满足 CI和CD的自动化需求，运行playbook 以及角色。&#xA;界面：</description>
    </item>
    <item>
      <title>Ansible 问答</title>
      <link>http://localhost:1313/docsgo/ansible/study/ansible-%E9%97%AE%E7%AD%94/</link>
      <pubDate>Thu, 11 Apr 2024 14:14:05 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/ansible-%E9%97%AE%E7%AD%94/</guid>
      <description>1、Ansible 最佳实践是什么&#xA;对于Devops来说，根据经验&#xA;如果有超过 100行的任务文件，我就开始考虑如何将其分解，一个playbook 超过百行，将要考虑如何分解 docker 容器最酷、最强大的特性之一是它们是不可变的。您不在 docker 容器上运行更新。使用更新的库构建新的 docker 映像后，您将停止旧容器并启动新容器。&#xA;并非所有基础设施都是一成不变的。其中一些是可变的。考虑一个标准的 Linux 服务器。它需要系统更新，需要安装应用程序依赖项，并且需要应用程序软件本身可用。这就是 Ansible 的用武之地。Ansible 用于远程配置可变基础设施。&#xA;2、Ansible 变量最佳位置&#xA;3、Ansible CICD&#xA;会用CI来测试Ansible Playbook、Role，与Ansible 分子测试一起使用&#xA;4、对于一个复杂的任务，涉及到很多文件，特别是如果它不是自己写的&#xA;我的问题是，对于那些在 k8s 之外运行虚拟机的人，如何仅使用 Terraform 配置或设置虚拟机？&#xA;你似乎明白了要点。 Terraform 无法取代 ansible，但您可以通过全力以赴进行容器编排来完全消除对 ansible 的需求。&#xA;根据我们自己的观察，我们在虚拟机上获得的性能比在同一虚拟机上运行的容器中获得的性能更好。&#xA;抽象级别&amp;hellip;裸机 &amp;gt; HyperVisor &amp;gt; VM &amp;gt; 容器&amp;hellip;.. 与裸机 &amp;gt; 操作系统 &amp;gt; 容器。&#xA;Terraform 旨在构建基础设施。它可以执行主机配置，但这不是它的主要目标。&#xA;Ansible 旨在配置系统。是的，它可以构建系统，但这不是它的主要目标&#xA;问题在于 Ansible 没有任何状态来跟踪之前的更改以及现在需要删除、创建或更新的内容。此外，Ansible 的相当一部分模块不是幂等的，在检查模式下也无法运行并获得准确的结果，这可能会导致重复工作。因此，您最好使用 Terraform 作为 IaC，并使用 Ansible 进行配置管理和构建黄金映像。&#xA;对于 IaC，您需要幂等性以及将当前状态与先前状态进行比较的能力。&#xA;我将 Ansible 用于云资源中的配置，并使用 Terraform 资源。让 Terraform 处理系统，让 Ansible 处理随时间变化的配置。效果超级好。</description>
    </item>
    <item>
      <title>Ansible Galaxy</title>
      <link>http://localhost:1313/docsgo/ansible/study/ansible-galaxy/</link>
      <pubDate>Thu, 11 Apr 2024 09:41:25 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/ansible-galaxy/</guid>
      <description>示例文件&#xA;root@ubuntu-c:~/ansible/episode/00-galaxy# ls ansible.cfg main.yml requiremerts.yml ansible.cfg&#xA;指定 role path [defaults] INVENTORY = inventory roles_path = ./roles main.yml&#xA;--- - name: install hosts: app become: true roles: - role: elliotweiser.osx-command-line-tools - role: geerlingguy.homebrew requiremerts.yml&#xA;--- roles: - name: elliotweiser.osx-command-line-tools version: 2.3.0 - name: geerlingguy.homebrew version: 4.0.0 执行安装请求：&#xA;ansible-galaxy install -r requiremerts.yml 确保 ansible playbook 正确&#xA;yamllint ansible-playbook &amp;ndash;syntax-check ansible-lint molecule test ansible-playbook &amp;ndash;check fail\assect</description>
    </item>
    <item>
      <title>Ansible Role</title>
      <link>http://localhost:1313/docsgo/ansible/study/4-ansible-role/</link>
      <pubDate>Wed, 10 Apr 2024 20:28:09 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/4-ansible-role/</guid>
      <description>handlers: - name: restart solr systemd: name: solr state: restarted enabled: yes 写为：&#xA;handlers: - ipmort_tasks: handlers/apache.yml 文件&#xA;root@ubuntu-c:/ansible/study/chapter4# cat handlers/apache.yml --- - name: restart solr systemd: name: solr state: restarted enabled: yes 作用：导入，开始运行之前&#xA;tasks部分：更具可读性&#xA;ipmort_tasks 作用：导入，开始运行之前 运行中产生的：动态定义 --- - hosts: solr become: true vars_files: - vars.yml pre_tasks: - name: Update yum yum: update_cache: yes handlers: - ipmort_tasks: handlers/apache.yml tasks: - ipmort_tasks: tasks/apache.yml - incude_tasks: tasks/logs.yml - ipmort_tasks: tasks/apache.yml - ipmort_tasks: tasks/apache.</description>
    </item>
    <item>
      <title>Ansible 变量</title>
      <link>http://localhost:1313/docsgo/ansible/study/3-ansible%E5%8F%98%E9%87%8F/</link>
      <pubDate>Wed, 10 Apr 2024 12:51:25 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/3-ansible%E5%8F%98%E9%87%8F/</guid>
      <description>Handler Playbook handlers, environment vars, and variables&#xA;handler: - name: restart httpd - name: restart nginx ... notifi: - restart httpd - restart nginx --- handler: - name: restart httpd systemd: ... notifi: restart nginx - name: restart nginx ... notifi: restart httpd handler 将在剧本末尾执行&#xA;如果想立刻重启：&#xA;- name: make restart handlers meta: flush_handlers 如果任务中有失败，那么久不会到最后一步执行handler&#xA;参数&#xA;--force-handlers Vars --- vars: k: v vars_files: - vars/main.yaml yaml&#xA;--- - name: install hosts: app become: true tasks: - name: Add env var lineinfile: path: &amp;#34;/etc/bashrc&amp;#34; regexp: &amp;#39;^ENV_VAR=&amp;#39; state: present line: &amp;#39;EVC_VAR=value&amp;#39; 使用 shell 模块会更简单</description>
    </item>
    <item>
      <title>Ansible Playbook</title>
      <link>http://localhost:1313/docsgo/ansible/study/2-playbook%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Tue, 09 Apr 2024 10:45:10 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/2-playbook%E7%AE%80%E4%BB%8B/</guid>
      <description>工作中大多时间使用的 playbook&#xA;传递清单文件 哪些服务器执行 命令 -f 指定并行、&amp;ndash;limit指定主机 -b：成为 root，默认使用 sudo&#xA;后台运行：&#xA;ansible multi -B 3600 -P 0 -a &amp;#34;yum -y update&amp;#34; -B 3600：这个选项设置了任务的超时时间（以秒为单位）&#xA;-P 0：这个选项设置了Ansible的轮询间隔（以秒为单位）。在这个例子中，Ansible将不会轮询任务的状态，也就是说，Ansible将会立即返回，而不会等待任务完成。&#xA;提供了一个JobID&#xA;ansible multi -b -m async_status -a &amp;#34;jid=j993071582105.3469&amp;#34; shell script&#xA;#!/bin/bash yum install --quiet -y httpd httpd-devel # copy config files cp httpd.conf /etc/httpd/conf/httpd.conf cp httpd-vhosts /etc/httpd/conf/httpd-vhosts.conf service httpd start chkconfig httpd on ansible playbook&#xA;root@ubuntu-c:~/ansible/study/chapter2# cat main.yml --- - hosts: solr become: true vars_files: - vars.</description>
    </item>
    <item>
      <title>Ansible 临时任务和清单组</title>
      <link>http://localhost:1313/docsgo/ansible/study/2-%E4%B8%B4%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%92%8C%E6%B8%85%E5%8D%95%E7%BB%84/</link>
      <pubDate>Mon, 08 Apr 2024 22:45:34 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/2-%E4%B8%B4%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%92%8C%E6%B8%85%E5%8D%95%E7%BB%84/</guid>
      <description>HOC&#xA;ansible 快速完成任务的一种方式&#xA;例如：&#xA;快速添加和删除特定用户的访问权限，可以使用这些来管理主机文件 主机文件、DNS文件，快速复制文件、重启服务等 不必编写剧本和测试剧本。&#xA;因为有事需要快速获取更改一些信息。&#xA;inenvtory 文件&#xA;[app] centos1 centos2 [db] centos3 ansible 默认情况下是 以并行运行 默认是 5，可以 使用 -f 指定&#xA;root@ubuntu-c:~/ansible/study/adhoc# ansible multi -a &amp;#39;hostname&amp;#39; -f 1 centos1 | CHANGED | rc=0 &amp;gt;&amp;gt; centos1 centos2 | CHANGED | rc=0 &amp;gt;&amp;gt; centos2 centos3 | CHANGED | rc=0 &amp;gt;&amp;gt; db-test 控制系统有足够的CPU和内存 甚至可以将并行设置成 100+&#xA;setup：服务器几乎所有信息&#xA;限制在一台服务器上运行&#xA;ansible multi -a &amp;#39;hostname&amp;#39; --limit &amp;#34;centos1&amp;#34; 可以使用正则匹配</description>
    </item>
    <item>
      <title>Ansible 简介</title>
      <link>http://localhost:1313/docsgo/ansible/study/1-ansible%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Mon, 08 Apr 2024 15:56:38 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/1-ansible%E7%AE%80%E4%BB%8B/</guid>
      <description>Ansible 简述 此前，很多的shell 脚本的编写，没有任何真正容易简单的事情。并不像是编写Shell脚本 并在服务器上运行那么简单，尤其是必须在服务器上安装东西。&#xA;Ansible的出现使事情变得更加简单：&#xA;不必了解某些特定的编程语言 基本上可以将 Shell 脚本简单的转换成 Ansible 脚本 - “剧本”，甚至无需使用特殊的 ansible 模块 或逻辑，非常轻松的运行所有服务器。 作为初级到中级的Linux 管理员，需要掌握大规模基础设施的自动化。&#xA;Devops for Ansible&#xA;Devops 对我来说 更多的是一种哲学，而不一定是一个职位或者角色。这种理念是开发和运维紧密联系。 当开发人员接管管道，从某种意义上来说，能够将开发和运维混合在一起。 仍然是需要 SRE 或 系统管理员来运行服务器并确保应用程序的正常运行，并且还有专门构建应用程序的开发人员。 从Ansible 历史&#xA;最初：允许在多台服务器上运行命令。 目标：清晰、完整、快速、高效和安全。 Ansible 通过SSH与机器服务器交互，无需安装代理-守护进程或者在服务器上为自动化工具提供端口。&#xA;安全：使用安全传输协议&#xA;很多时候自动化的动机时：希望能够设置服务器，或者构建容器。&#xA;喜欢ansible 原因之一：可以将 shell脚本，shell 命令以及其他的任务转移到Ansible中，让Ansible去做它们。&#xA;安装 Ansible pip3 install ansible 版本：&#xA;ansible@ubuntu-c:~$ ansible --version ansible [core 2.14.11] config file = None configured module search path = [&amp;#39;/home/ansible/.ansible/plugins/modules&amp;#39;, &amp;#39;/usr/share/ansible/plugins/modules&amp;#39;] ansible python module location = /usr/local/lib/python3.</description>
    </item>
    <item>
      <title>Nginx Ingress重定向</title>
      <link>http://localhost:1313/docsgo/kubernetes/ingress/nginx-ingress%E9%87%8D%E5%AE%9A%E5%90%91/</link>
      <pubDate>Mon, 08 Apr 2024 10:46:46 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/ingress/nginx-ingress%E9%87%8D%E5%AE%9A%E5%90%91/</guid>
      <description>官网参考：https://kubernetes.github.io/ingress-nginx/examples/rewrite/&#xA;metadata: annotations: nginx.ingress.kubernetes.io/app-root: /pumer/project/** 测试访问：&#xA;[root@k8sworker1 ~]# curl portal.**.com &amp;lt;html&amp;gt; &amp;lt;head&amp;gt;&amp;lt;title&amp;gt;302 Found&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt; &amp;lt;body bgcolor=&amp;#34;white&amp;#34;&amp;gt; &amp;lt;center&amp;gt;&amp;lt;h1&amp;gt;302 Found&amp;lt;/h1&amp;gt;&amp;lt;/center&amp;gt; &amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx/1.13.9&amp;lt;/center&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; </description>
    </item>
    <item>
      <title>Ansible 入门</title>
      <link>http://localhost:1313/docsgo/ansible/study/0-%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 07 Apr 2024 21:14:26 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/ansible/study/0-%E5%85%A5%E9%97%A8/</guid>
      <description>ansible 和 Terraform 是最受欢迎的基础设施代码之一&#xA;从表面上看，Ansible 可以完成与 Terraform 相同类型的基础设施配置。然而，它们在架构上有根本的不同——Ansible 是一个命令式脚本执行引擎，它将按照代码中列出的顺序运行任务，而 Terraform 是一个声明式执行引擎，它将并行化彼此不直接依赖的任务。因此，除了非常小的代码库之外，Terraform 的执行速度比 Ansible 快得多。&#xA;（顺便说一句，大规模执行速度慢是 Ansible 的主要弱点。）&#xA;Terraform 基于图形的性质还使得可以使用与创建基础设施完全相同的代码来销毁基础设施，而 Ansible 需要单独的剧本来创建和销毁。对于定期创建和销毁的环境（例如，开发/测试/登台），Terraform 的方法既可以大幅提高生产力，又可以减少人为错误的机会。&#xA;最后，虽然这不一定是 Ansible 的技术缺陷，但在基础设施配置方面，Terraform 迄今为止拥有最多的社区和开发理念。与任何其他基础设施配置工具相比，您更有可能找到 Terraform 的支持资源，并且您希望以编程方式配置的新产品可能会首先在 Terraform 中获得支持。&#xA;Ansible：开源的配置管理、软件配置和应用部署工具集。&#xA;软件定义基础设施 Modules：Ansible成功的一个主要因素是因为有大量的模块可供公开使用。&#xA;🚀 Ansble 实验环境 环境：Docker - MAC（Docker Desktop） Docker compose 建立环境 Ansible 是无代理的架构，SSH 配置主机之间无密码连接 🧪实验&#xA;访问：http://localhost:1000&#xA;密码：root/ansible、password&#xA;连接到其他主机不希望使用密码：&#xA;SSH 私有和公钥 控制端 私钥将与被控端的公钥进行验证&#xA;ansible@ubuntu-c:~$ ssh-keygen ... +---[RSA 3072]----+ |*...==B=oo. | |oo .o++oo. o | |. . o o= + .</description>
    </item>
    <item>
      <title>第1章： DevSecOps-入门</title>
      <link>http://localhost:1313/docsgo/devsecops/0-%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 07 Apr 2024 21:03:20 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devsecops/0-%E5%85%A5%E9%97%A8/</guid>
      <description>先决条件：&#xA;当 Devops 解决了应用程序的自动发布，需要将安全引入 Devops&#xA;CI/CI 工具 【这些是先绝条件-必须的】&#xA;Jenkins Gitlab CI/CD Github Actions 还有：Linux、Docker、Ansible、Terrafrom、Py、Go、云等&#xA;安全是一个非常广泛的话题。&#xA;学习保护之前，学习安全的核心概念。与其仅仅学习如何执行安全扫描工具来实现自动化，复制粘贴。&#xA;并非只是要学习工具使用，还需背后的概念和目的。 安全三大类：&#xA;应用安全 基础设施&amp;amp;云安全 Kubernetes安全 </description>
    </item>
    <item>
      <title>基础设施即代码</title>
      <link>http://localhost:1313/docsgo/terraform/%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%8D%B3%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Sat, 06 Apr 2024 21:44:54 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/terraform/%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%8D%B3%E4%BB%A3%E7%A0%81/</guid>
      <description></description>
    </item>
    <item>
      <title>YugabyteDB</title>
      <link>http://localhost:1313/docsgo/monitor/yugabytedb/</link>
      <pubDate>Wed, 03 Apr 2024 15:30:58 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/yugabytedb/</guid>
      <description>参考：https://docs.yugabyte.com/preview/explore/observability/prometheus-integration/macos/&#xA;下载:&#xA;wget https://github.com/yugabyte/yb-sample-apps/releases/download/v1.4.1/yb-sample-apps.jar -O yb-sample-apps.jar 运行&#xA;java -jar ./yb-sample-apps.jar \ --workload CassandraKeyValue \ --nodes 127.0.0.1:9043 \ --num_threads_read 1 \ --num_threads_write 1 java -jar ./yb-sample-apps.jar \ --workload CassandraKeyValue \ --nodes 10.61.200.238:5433 \ --num_threads_read 1 \ --num_threads_write 1 \ --username thingswise_admin \ --password 5gwqLJqeIPHBue0cDSyJN05fo4deEf38QW2guas41zNw6qlrbqm8AaCG4Embg8AbAdoA1yq2DWbdw1CQHgm484NE7AQGHxc7c281dWpUWf9JZGs2e2PckrAd9D1bVNDf java -jar yb-sample-apps.jar --workload CassandraKeyValue --nodes 10.61.200.238:9043 --username thingswise_admin --password 5gwqLJqeIPHBue0cDSyJN05fo4deEf38QW2guas41zNw6qlrbqm8AaCG4Embg8AbAdoA1yq2DWbdw1CQHgm484NE7AQGHxc7c281dWpUWf9JZGs2e2PckrAd9D1bVNDf --ssl_key /etc/ssl/yugabyte/yugabytedb.crt java -jar yb-sample-apps.jar \ --workload CassandraKeyValue \ --nodes 127.0.0.1:9042 \ --username thingswise_admin \ --password 5gwqLJqeIPHBue0cDSyJN05fo4deEf38QW2guas41zNw6qlrbqm8AaCG4Embg8AbAdoA1yq2DWbdw1CQHgm484NE7AQGHxc7c281dWpUWf9JZGs2e2PckrAd9D1bVNDf \ --ssl /etc/ssl/yugabyte/yugabytedb.</description>
    </item>
    <item>
      <title>监控可观测性</title>
      <link>http://localhost:1313/docsgo/monitor/%E7%9B%91%E6%8E%A7%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/</link>
      <pubDate>Tue, 02 Apr 2024 09:42:02 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/%E7%9B%91%E6%8E%A7%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/</guid>
      <description>监控简述 概述 一个技术的出现必定有它的原因（解决了什么问题）&#xA;在现代的 DevOps 中手动处理变得越来越复杂，因此需要更多的自动化；&#xA;通常会拥有：&#xA;多个项目、多个集群 运行非常多的容器，并且有成千上百的不同进程在运行 基础设施和 应用是相连的 因此需要去保持这样的设置去平稳运行、并且没有应用程序去停机，时间是非常重要的，也是有挑战性的。&#xA;需要解决：&#xA;无法了解硬件级别或上层发生的情况 应用程序级别、如 Error、响应延迟、硬件故障、或过载，可能耗尽资源等 在如此复杂的环境中，当部署大量的服务和应用程序时，可能出现很多问题，其中任何一个都可能导致程序崩溃，并且导致其他服务失败。&#xA;突然的应用程序对用户变得不可用，必须快速的确定这整个应用程序中是到底出现了什么问题 并且在手动调试过程中可能会很困难 且 耗时 示例场景 服务器内存不足，并启动了一个正在运行的容器，该容器在 Kubernetes 集群中两个数据库 Pod 之间提供数据，这反过来又导致：&#xA;两个数据库部分失败，该数据库被身份验证服务器使用，该服务器也停止工作，因为数据库变得不可用 然后依赖于该身份验证服务的应用程序无法再对 UI 中的用户进行身份验证 用户角度：只看到 UI 中的错误，无法登陆 所以：遇到这种情况，如何知道实际上出了什么问题，对集群内部发生的情况如果看不到事件发生的整个事件链的红线，只看到错误，如何去排查修复，以便检查服务是否有返回并运行正常，是否现实异常，服务是否在正常运行，为什么会崩溃。&#xA;拥有一个工具使得搜索问题过程更加高效&#xA;持续监控服务是否正常运行 在一项服务崩溃时立即那个运维人员发出告警 以便确切的知道发生了什么，甚至可以在问题发生前识别问题 提醒运维人员 例如在上述例子中，可以去定期检查每台 服务器的内存，做内存上限告警（当在一段时间内飙升到某个值，例如70%）或者不间断的去增加。&#xA;另外一种情况：突然停止看到应用程序的日志，因为 elasticsear 可接受的日志因为磁盘空间的不足或 elasticsear 再次达到为其分配的存储限制， 监控工具将 持续检查磁盘空间 ，可以额告诉监控何时触发告警。&#xA;第三种情况：即应用程序由于一项服务奔溃而突然变得很慢，并开始在网络中循环发生数百条错误信息，这会产生高网络流量并减慢其他服务的速度，有一个工具可以检测网络负载中的此类峰值，并且告诉哪个服务负责导致的，可以及时发出告警 解决这个问题。&#xA;自动监控和警报：Promethers 监视特定的事物，该事物可以是如何东西，可以是整个Linux服务器、Windows服务器、也可以是独立的Apache服务器、单个应用程序 或 像数据库这样的服务，以及Prometheus 监视的哪些东西称为目标.&#xA;每个目标（targets）都有Linux serevr的监视单位，可以是 CPU、内存、磁盘、网路等，也可以是异常数据请求、请求持续时间以及 想要监视的目标的单位称之为 指标，指标是保存着 TSDB&#xA;收集指标 一个有趣的问题：如何去从目标收集这些指标&#xA;prometheus 从 http 端点从 metrics 中提取指标数据 默认情况下是 主机IP+端口:/metrics 目标必须公开/metrics接口，且必须采用 prometheus能够理解的格式 一些服务本身有/metrics 一些没有，因此需要额外的组件来执行此操作 ，该组件是导出器 Exporter</description>
    </item>
    <item>
      <title>Systemd创建Linux服务</title>
      <link>http://localhost:1313/docsgo/shell/systemd%E5%88%9B%E5%BB%BAlinux%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Mon, 01 Apr 2024 17:03:58 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/shell/systemd%E5%88%9B%E5%BB%BAlinux%E6%9C%8D%E5%8A%A1/</guid>
      <description>Systemd创建Linux服务 🤔 需要创建一个脚本并在后台运行它&#xA;可以采取几种方法 也许最简单的方法就是在命令末尾添加一个&amp;amp; 另外，如果想关闭终端，追加nohup。⚠️ 如果的脚本由于某种原因存在，需要手动重新启动它。 更好的方法是使用Linux 的： systemd 展示如何创建一个简单的 systemd 服务，该服务可以在后台运行脚本并在出现故障时重新启动它&#xA;systemd 启动示例 创建一个简单的 Python HTTP 服务器 vim my_server.py 接受 HTTP GET 请求并将Hello字符串返回给客户端 from http.server import BaseHTTPRequestHandler, HTTPServer hostName = &amp;#34;localhost&amp;#34; serverPort = 8080 class MyServer(BaseHTTPRequestHandler): def do_GET(self): self.send_response(200) self.send_header(&amp;#34;Content-type&amp;#34;, &amp;#34;text/html&amp;#34;) self.end_headers() self.wfile.write(bytes(&amp;#34;Hello\n&amp;#34;, &amp;#34;utf-8&amp;#34;)) if __name__ == &amp;#34;__main__&amp;#34;: webServer = HTTPServer((hostName, serverPort), MyServer) print(&amp;#34;Server started http://%s:%s&amp;#34; % (hostName, serverPort)) try: webServer.serve_forever() except KeyboardInterrupt: pass webServer.server_close() 尝试在前台运行，确保py脚本正常&#xA;python3 my_server.py 然后打开一个新窗口并，尝试使用命令访问服务器curl。</description>
    </item>
    <item>
      <title>Root Ssh Login Sh</title>
      <link>http://localhost:1313/docsgo/shell/root-ssh-login-sh/</link>
      <pubDate>Mon, 01 Apr 2024 15:58:40 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/shell/root-ssh-login-sh/</guid>
      <description>配置SSH以允许root用户无密码登录&#xA;脚本：&#xA;#!/bin/bash print_script_header() { echo &amp;#34;-----------------------------------------------&amp;#34; echo &amp;#34;# 脚本: root_ssh_login.sh&amp;#34; echo &amp;#34;# 描述: 配置SSH以允许root用户无密码登录&amp;#34; echo &amp;#34;# 作者:&amp;#34; echo &amp;#34;# 日期: 2024&amp;#34; echo &amp;#34;-----------------------------------------------&amp;#34; } # 示例用法 users=(&amp;#34;root&amp;#34;) input(){ # 提示用户输入节点，以空格分隔 read -p &amp;#34;请输入节点名称（以空格分隔）: &amp;#34; nodes_input # 将输入的节点字符串分割成数组 IFS=&amp;#39; &amp;#39; read -ra nodes &amp;lt;&amp;lt;&amp;lt; &amp;#34;$nodes_input&amp;#34; } # 函数：提示用户输入密码并创建password.txt prompt_for_password() { read -s -p &amp;#34;请输入密码: &amp;#34; password echo &amp;#34;$password&amp;#34; &amp;gt; /tmp/password.txt } # 函数：检查并使用yum安装sshpass install_sshpass() { if ! command -v sshpass &amp;amp;&amp;gt; /dev/null; then echo &amp;#34;提示：sshpass未安装，正在安装.</description>
    </item>
    <item>
      <title>Kubeadm部署k8s集群</title>
      <link>http://localhost:1313/docsgo/kubernetes/kubeadm%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 01 Apr 2024 11:18:20 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/kubernetes/kubeadm%E5%AE%89%E8%A3%85%E9%9B%86%E7%BE%A4/</guid>
      <description>Kubernetes 注：部署环境为离线环境，镜像包需要推送到自建 Harbor 仓库。&#xA;在线环境部署 与 该文章最大区别就是无需手动准备镜像，仅此而已。&#xA;准备工作 1、Harbor 部署 harbor-offline-installer-v2.1.2.tgz&#xA;https://github.com/goharbor/harbor/releases/tag/v2.1.2&#xA;可参考安装文档：官方：https://goharbor.io/docs/2.1.0/install-config/quick-install-script/&#xA;上传harbor包，与 docker-compose-Linux-x86_64&#xA;mv /tmp/docker-compose-Linux-x86_64 /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 编辑配置文件&#xA;tar -zxvf /tmp/harbor-offline-installer-v2.1.2.tgz -C /root 进入解压的 harbor 目录&#xA;⚠️：拷贝harbor.yml的备份文件为 harbor.yml&#xA;编辑文件 /root/harbor/harbor.yml 注释掉https的相关配置 默认端口：8080 主机地址：hostname: 修改为主机 IP 存储目录: data_volume: /data/harbor 运行脚本：&#xA;bash install.sh 创建Harbor 库 bash create_project_harbor.sh&#xA;⚠️：按需添加需要的库名称，运行该脚本&#xA;#!/usr/bin/env bash url=&amp;#34;https://dockerhub.kubekey.local&amp;#34; user=&amp;#34;admin&amp;#34; passwd=&amp;#34;Harbor12345&amp;#34; harbor_projects=(library kubesphere calico ) for project in &amp;#34;${harbor_projects[@]}&amp;#34;; do echo &amp;#34;creating $project&amp;#34; curl -u &amp;#34;${user}:${passwd}&amp;#34; -X POST -H &amp;#34;Content-Type: application/json&amp;#34; &amp;#34;${url}/api/v2.</description>
    </item>
    <item>
      <title>Jumpserver</title>
      <link>http://localhost:1313/docsgo/other/jumpserver/</link>
      <pubDate>Fri, 29 Mar 2024 09:46:46 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/other/jumpserver/</guid>
      <description>官网：https://www.jumpserver.org/index.html&#xA;统一IT资产访问入口：&#xA;通过登录JumpServer可以访问已授权的服务器，通过统一的门户访问所有的IT资产&#xA;安全稳定运行的保障&#xA;​&#x9;通过Web页面和SSH客户端访问JumpServer。为了提升安全等级，JumpServer支持MFA多因子认证的方式，并且支持录像审计和SSH协议访问。JumpServer也完整具备4A（即身份验证、授权控制、账号管理、安全审计）四大核心功能，为服务器、网络设备、数据库和安全设备等内网设备提供了统一的安全管理保障&#xA;MFA认证：多重身份认证&#xA;登陆时加了一层安全层，要求用户使用 因素：&#xA;用户已知：用户名 、 密码 MFA：认证器得到验证码 如果别人窃取了 用户密码，那么他还需要窃取你的手机&#xA;访问：Https&#xA;数据库</description>
    </item>
    <item>
      <title>Mysqldump</title>
      <link>http://localhost:1313/docsgo/shell/mysqldump/</link>
      <pubDate>Thu, 28 Mar 2024 16:11:37 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/shell/mysqldump/</guid>
      <description>🍭 mysqldump ✅ 执行 mysqldump.sh 完成全量备份 变量 (必须):&#xA;BACKUP_DIR：备份目录 MYSQL_UNAME：用户 MYSQL_PWORD：密码 PATH：mysqldump命令路径 KEEP_BACKUPS_FOR：保留天数(默认7天) 🌐 恢复(示例)&#xA;for file in ./2024-03-07/*.sql.gz; do gunzip &amp;gt; &amp;#34;$file&amp;#34; | mysql -u your_username -p your_database_name; done ⛳️ cron(示例)&#xA;例：每天定时凌晨1点10分备份数据库&#xA;10 1 * * * /bin/bash /data/mysql/.sh/mysql_backup.sh 脚本：&#xA;#!/bin/bash #============================================================================== #TITLE: mysql_backup.sh #DESCRIPTION: 自动执行日常 mysql 备份的脚本 #DATE: 2024.03.07 #VERSION: 0.1 #USAGE: ./mysql_backup.sh #CRON: # 每天凌晨 00:00 执行数据库备份的 cron 示例 # 0 0 * * * /Users/[your user name]/scripts/mysql_backup.</description>
    </item>
    <item>
      <title>Vmauth</title>
      <link>http://localhost:1313/docsgo/monitor/victoriametrics/vmauth/</link>
      <pubDate>Wed, 27 Mar 2024 16:38:42 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/victoriametrics/vmauth/</guid>
      <description>简单身份验证代理&#xA;下载：https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.99.0/vmutils-linux-amd64-v1.99.0.tar.gz&#xA;减压到：/usr/local/bin&#xA;system 文件&#xA;使用了TLS 加密 配置文件参考官方文档即可 cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/systemd/system/vmauth.service [Unit] Description=Description=vmauth.service After=network.target [Service] Type=simple ExecStart=/usr/local/bin/vmauth-prod -auth.config=/etc/auth/config.yml -tls -tlsCertFile=/root/.ssh/cert.pem -tlsKeyFile=/root/.ssh/key.pem SyslogIdentifier=victoriametrics Restart=always [Install] WantedBy=multi-user.target EOF </description>
    </item>
    <item>
      <title>VictoriaMetrics</title>
      <link>http://localhost:1313/docsgo/monitor/victoriametrics/victoriametrics/</link>
      <pubDate>Wed, 27 Mar 2024 16:33:08 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/victoriametrics/victoriametrics/</guid>
      <description>安装方式多种参考官网文档&#xA;二进制安装：&#xA;下载：https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.99.0/victoria-metrics-linux-amd64-v1.99.0.tar.gz 解压到 /usr/local/bin&#xA;创建数据目录：例如 /data/victoria-metrics 启动文件：&#xA;兼容 prometheus 配置文件格式 cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/systemd/system/victoria-metrics.service [Unit] Description=Description=VictoriaMetrics service After=network.target [Service] Type=simple LimitNOFILE=2097152 ExecStart=/usr/local/bin/victoria-metrics-prod -storageDataPath=/data/victoria-metrics -promscrape.config=/etc/victoriametrics/prometheus.yaml SyslogIdentifier=victoriametrics Restart=always PrivateTmp=yes ProtectHome=yes NoNewPrivileges=yes ProtectSystem=full [Install] WantedBy=multi-user.target 暴露端口：8428</description>
    </item>
    <item>
      <title>Alertmanager</title>
      <link>http://localhost:1313/docsgo/monitor/alert/alertmanager/</link>
      <pubDate>Wed, 27 Mar 2024 16:03:21 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/alert/alertmanager/</guid>
      <description>二进制安装：&#xA;下载：https://github.com/prometheus/alertmanager/releases/download/v0.27.0/alertmanager-0.27.0.linux-amd64.tar.gz&#xA;下载减压 - &amp;gt; /usr/local/bin&#xA;cta &amp;lt;&amp;lt;EOF &amp;gt;/etc/systemd/system/alertmanager.service ### Alertmanager systemd [Unit] Description=Alertmanager After=network-online.target [Service] User=alertmanager Group=alertmanager Type=simple ExecStart=/usr/local/bin/alertmanager --config.file=/etc/alertmanager/alertmanager.yml Restart=always [Install] WantedBy=multi-user.target EOF 配置文件：alertmanager.yml&#xA;参考官方配置 示例：企业微信&#xA;global: resolve_timeout: 5m route: group_by: [&amp;#39;alertname&amp;#39;] group_wait: 10s group_interval: 1m repeat_interval: 30m receiver: &amp;#39;web.hook&amp;#39; receivers: - name: &amp;#39;web.hook&amp;#39; webhook_configs: - url: &amp;#39;http://localhost:8999/webhook&amp;#39; send_resolved: true 访问：9093端口</description>
    </item>
    <item>
      <title>Vmagent</title>
      <link>http://localhost:1313/docsgo/monitor/victoriametrics/vmagent/</link>
      <pubDate>Wed, 27 Mar 2024 15:48:16 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/victoriametrics/vmagent/</guid>
      <description>接入腾讯云监控，vmagent 会将监控数据 pull 到腾讯云 victoriametrics TSDB&#xA;前提 下载包 wget https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.99.0/vmutils-linux-amd64-v1.99.0.tar.gz 证书文件放置在 /etc/ssl/certs cert.pem key.pem 安全 证书：&#xA;🎉 用于 vmagent传输数据 TLS加密&#xA;cat &amp;lt;&amp;lt;EOF &amp;gt; openssl.cnf [req] req_extensions = v3_req distinguished_name = req_distinguished_name [req_distinguished_name] [v3_req] basicConstraints = CA:FALSE keyUsage = nonRepudiation, digitalSignature, keyEncipherment subjectAltName = @alt_names [alt_names] IP.1 = 1.15.176.240 EOF openssl req -x509 -nodes -days 3650 -newkey rsa:2048 \ -keyout key.pem -out cert.pem \ -subj &amp;#34;/C=CN/ST=shanxi/L=xian/O=IT/CN=monitor&amp;#34; \ -config.yaml openssl.cnf 接入环境配置：&#xA;cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/ssl/certs/cert.</description>
    </item>
    <item>
      <title>Git</title>
      <link>http://localhost:1313/docsgo/devops/git/git/</link>
      <pubDate>Wed, 27 Mar 2024 13:10:39 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/devops/git/git/</guid>
      <description>🏆 Version Control [toc]&#xA;Git 在软件开发中，用于管理应用程序代码&#xA;版本控制概念 如何实现工作 创建Git仓库 本地使用 Git 命令行工具 所有相关的 Git 注释 一些有用的概念：恢复错误，合并冲突 分支的概念 🧬 贯穿整个模块，同时学习不同的概念 ，使用Git的最佳实践&#xA;🤔 What is Version Control 🌰：一个团队、公司、大项目 多个开发同时在做的事情 - 开发应用程序。&#xA;构建前端、后端、数据库连接等等 共享代码，多个人对同一文件做了操作，进行了更改。&#xA;从 代码仓库存储到本地，做一些改变后推送到代码仓库，下一个开发人员就可以获取到代码。&#xA;持续集成：&#xA;开发中，使用相同代码的开发人员，最好的做法是不断的推拉，通常来自存储库，因此不需要合并重叠的巨大变化，也可以轻松排序不同的变化。 ‼️ 如果有人弄乱了代码和更改&#xA;每一次提交都是一个历史版本，可以还原提交，这就是版本控制的来源 每个更改都有提示信息【意味着提交不应该很大】 🚀 如何实现工作 远端仓库 本地仓库 历史：日志 暂停：被锁定的部分 git客户端 工作目录 &amp;ndash;&amp;gt; git add 暂停区域 &amp;ndash;&amp;gt; git commint 本地仓库 git push 远端仓库&#xA;⚙️ 设置Git 仓库 什么是Git 存储库&#xA;存储库：GitHub、GitLab 私人、公司 公司不会在公共场所托管他们的代码，Git 存储库的云厂商，有自己的存储仓库托管在公司当中。&#xA;🎯 git客户端 连接 gitlab</description>
    </item>
    <item>
      <title>Rulers</title>
      <link>http://localhost:1313/docsgo/monitor/alert/rulers/</link>
      <pubDate>Tue, 26 Mar 2024 11:27:25 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/alert/rulers/</guid>
      <description>访问：告警规则集合链接&#xA;Node Exporter # 主机和硬件相关的告警规则 groups: # 磁盘使用率告警 - name: 磁盘使用率告警 rules: - alert: 磁盘使用率告警 expr: floor(((node_filesystem_size_bytes{heihutao!~&amp;#34;heihutao-tw-dev|heihutao-tw-test|heihutao-tw-dp&amp;#34;} - node_filesystem_free_bytes) * 100) / (node_filesystem_avail_bytes + node_filesystem_size_bytes - node_filesystem_free_bytes)) &amp;gt; 85 for: 1m labels: severity: 严重 annotations: summary: &amp;#34;磁盘使用率超过85% (实例 {{ $labels.instance }})&amp;#34; description: &amp;#34;设备 {{ $labels.device }} 挂载在 {{ $labels.mountpoint }} 的磁盘使用率超过了 85%。(当前值: {{ $value }}%)&amp;#34; # 内存使用率告警 - name: 内存告警规则 rules: - alert: &amp;#34;内存使用率告警&amp;#34; expr: floor((node_memory_MemTotal_bytes{heihutao!~&amp;#34;heihutao-tw-dev|heihutao-tw-test|heihutao-tw-dp&amp;#34;} - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)) / node_memory_MemTotal_bytes * 100) &amp;gt; 85 for: 3m labels: severity: 严重 annotations: summary: &amp;#34;内存使用率超过85% (实例 {{ $labels.</description>
    </item>
    <item>
      <title>Garfana</title>
      <link>http://localhost:1313/docsgo/monitor/grafana/garfana/</link>
      <pubDate>Tue, 26 Mar 2024 10:57:21 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/grafana/garfana/</guid>
      <description>安装Grafna 访问：https://grafana.com/docs/grafana/latest/setup-grafana/installation/&#xA;设置 Grafana HTTPS 以确保网络流量安全 访问：https://grafana.com/docs/grafana/latest/setup-grafana/set-up-https/&#xA;步骤&#xA;生成自签名证书 生成自签名证书 打开该grafana.ini文件并编辑以下配置参数：&#xA;[server] http_addr = http_port = 3000 domain = mysite.com root_url = https://subdomain.mysite.com:3000 cert_key = /etc/grafana/grafana.key cert_file = /etc/grafana/grafana.crt enforce_domain = False protocol = https 注意：SSL 流量的标准端口是 443，您可以使用它来代替 Grafana 的默认端口 3000。</description>
    </item>
    <item>
      <title>Kube State Metrics</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/kube-state-metrics/</link>
      <pubDate>Mon, 25 Mar 2024 10:23:51 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/kube-state-metrics/</guid>
      <description>适用于集群版本，k8s v1.9&#xA;前提准备：&#xA;准备镜像 docker pull bitnami/kube-state-metrics:1.6.0 上传到所有worker节点&#xA;🎉 完成上述步骤再继续&#xA;部署：&#xA;--- apiVersion: v1 kind: ServiceAccount metadata: labels: app: kube-state-metrics name: kube-state-metrics namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: kube-state-metrics rules: - apiGroups: [&amp;#34;&amp;#34;] resources: - configmaps - secrets - nodes - pods - services - resourcequotas - replicationcontrollers - limitranges - persistentvolumeclaims - persistentvolumes - namespaces - endpoints verbs: [&amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;] - apiGroups: [&amp;#34;extensions&amp;#34;] resources: - daemonsets - deployments - replicasets - ingresses verbs: [&amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;] - apiGroups: [&amp;#34;apps&amp;#34;] resources: - daemonsets - deployments - replicasets - statefulsets verbs: [&amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;] - apiGroups: [&amp;#34;batch&amp;#34;] resources: - cronjobs - jobs verbs: [&amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;] - apiGroups: [&amp;#34;autoscaling&amp;#34;] resources: - horizontalpodautoscalers verbs: [&amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;] - apiGroups: [&amp;#34;policy&amp;#34;] resources: - poddisruptionbudgets verbs: [&amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;] - apiGroups: [&amp;#34;certificates.</description>
    </item>
    <item>
      <title>Node Exporter</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/node-exporter/</link>
      <pubDate>Mon, 25 Mar 2024 09:28:48 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/node-exporter/</guid>
      <description>🎉 默认端口 9100，因为与业务端口冲突，所以此处为9101&#xA;node exporter 1.下载&#xA;wget https://github.com/prometheus/node_exporter/releases/download/v1.7.0/node_exporter-1.7.0.linux-amd64.tar.gz 2.减压后node_exporter移动&#xA;tar -zxvf node_exporter-1.7.0.linux-amd64.tar.gz -C /usr/local/bin/ --strip-components=1 3.service 文件&#xA;端口默认9100，会与yugabyte 端口冲突&#xA;cat &amp;lt;&amp;lt;EOF | tee /etc/systemd/system/node_exporter.service [Unit] Description=Node Exporter After=network.target [Service] Type=simple ExecStart=/usr/local/bin/node_exporter --web.listen-address=:9101 Restart=always [Install] WantedBy=multi-user.target EOF 启动服务 systemctl daemon-reload systemctl restart node_exporter.service systemctl status node_exporter.service systemctl enable node_exporter.service 接入：&#xA;- job_name: &amp;#39;node&amp;#39; static_configs: - targets: [&amp;#39;localhost:9101&amp;#39;] </description>
    </item>
    <item>
      <title>Mysql Exporter</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/mysql-exporter/</link>
      <pubDate>Mon, 25 Mar 2024 09:28:39 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/mysql-exporter/</guid>
      <description>🎉 暴露端口 9104&#xA;创建 /etc/mysqlexporter 目录并在其中创建 .my.cnf 文件，该文件包含 MySQL 用户名和密码。 🔔 user、password 数据库用户密码&#xA;mkdir -p /etc/mysqlexporter echo -e &amp;#34;[client]\nuser=$user\npassword=$password&amp;#34; &amp;gt; /etc/mysqlexporter/.my.cnf 将 mysqld_exporter 复制到 /usr/local/bin/ 目录。 cp ./bin/mysqld_exporter /usr/local/bin/ 创建一个名为 mysql_exporter.service 的 systemd 服务文件，该文件在 /etc/systemd/system/ 目录下。 cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/systemd/system/mysql_exporter.service [Unit] Description=mysql Exporter After=network.target [Service] Type=simple ExecStart=/usr/local/bin/mysqld_exporter --config.my-cnf=/etc/mysqlexporter/.my.cnf [Install] WantedBy=multi-user.target EOF 重新加载 systemd 的配置，启动 mysql_exporter.service 服务，并将其设置为开机启动。 systemctl daemon-reload systemctl start mysql_exporter.service systemctl enable mysql_exporter.service 验证 curl 127.0.0.1:9104/metrics 接入：&#xA;- job_name: &amp;#39;mysql&amp;#39; static_configs: - targets: [&amp;#39;mysql-exporter:9104&amp;#39;] Grafana 模版 ID ：17320</description>
    </item>
    <item>
      <title>Mongodb Exporter</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/mongodb-exporter/</link>
      <pubDate>Mon, 25 Mar 2024 09:28:25 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/mongodb-exporter/</guid>
      <description>🎉 mongodb exporter&#xA;下载：&#xA;wget https://github.com/percona/mongodb_exporter/releases/download/v0.11.2/mongodb_exporter-0.11.2.linux-amd64.tar.gz 减压后将 mongodb_exporter 二进制文件移动：&#xA;mv mongodb_exporter /usr/local/bin/ 在 MongoDB 中创建一个名为 prometheus 的用户&#xA;进入mongodb mongo mongo.skydns.local --ssl --sslPEMKeyFile /etc/ssl/mongo/client.pem --sslCAFile /etc/ssl/mongo/ca.crt --authenticationDatabase &amp;#39;$external&amp;#39; --authenticationMechanism MONGODB-X509 创建用户 use admin db.createUser({ user: &amp;#34;prometheus&amp;#34;, pwd: &amp;#34;prometheus&amp;#34;, roles: [ { role: &amp;#34;read&amp;#34;, db: &amp;#34;admin&amp;#34; }, { role: &amp;#34;readAnyDatabase&amp;#34;, db: &amp;#34;admin&amp;#34; }, { role: &amp;#34;clusterMonitor&amp;#34;, db: &amp;#34;admin&amp;#34; } ] }); 创建service文件&#xA;‼️ 修改证书路径 和 IP&#xA;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/systemd/system/mongodb_exporter.service [Unit] Description=mongodb_exporter After=network.</description>
    </item>
    <item>
      <title>Etcd Exporter</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/etcd-exporter/</link>
      <pubDate>Mon, 25 Mar 2024 09:28:11 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/etcd-exporter/</guid>
      <description>特定环境，每个节点 /etc/ssl/etcd/ssl 有etcd 证书&#xA;将以下配置写入：vmagent.yaml ‼️ 注意修改证书名为实际证书名，修改 etcd-ip&#xA;- job_name: &amp;#34;etcd&amp;#34; scheme: https tls_config: insecure_skip_verify: true cert_file: /etc/ssl/etcd/ssl/node-dev-master.pem key_file: /etc/ssl/etcd/ssl/node-dev-master-key.pem ca_file: /etc/ssl/etcd/ssl/ca.pem static_configs: - targets: [&amp;#39;etcd-ip1:2379&amp;#39;,&amp;#39;etcd-ip2:2379&amp;#39;,&amp;#39;etcd-ip3:2379&amp;#39;] </description>
    </item>
    <item>
      <title>Elasticsearch Exporter</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/elasticsearch-exporter/</link>
      <pubDate>Mon, 25 Mar 2024 09:27:13 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/elasticsearch-exporter/</guid>
      <description>监控 9114端口&#xA;下载减压：&#xA;wget https://github.com/prometheus-community/elasticsearch_exporter/releases/download/v1.5.0/elasticsearch_exporter-1.5.0.linux-amd64.tar.gz 2.减压后node_exporter移动&#xA;cp elasticsearch_exporter-1.5.0.linux-amd64/elasticsearch_exporter /usr/local/bin/ 3.service 文件&#xA;⚠️ &amp;ndash;es.uri 参数地址指定为 elasticsearch 节点IP&#xA;cat &amp;lt;&amp;lt;EOF | tee /etc/systemd/system/elasticsearch_exporter.service [Unit] Description=elasticsearch_exporter After=network.target [Service] Type=simple ExecStart=/usr/local/bin/elasticsearch_exporter --es.uri http://10.61.200.236:9200 --web.listen-address 0.0.0.0:9114 Restart=always [Install] WantedBy=multi-user.target EOF 启动服务 systemctl daemon-reload systemctl restart elasticsearch_exporter systemctl status elasticsearch_exporter systemctl enable elasticsearch_exporter 接入： - job_name: &amp;#39;elasticsearch_exporter&amp;#39; static_configs: - targets: [&amp;#39;10.61.200.236:9114&amp;#39;] Grafana 导入ID：14191</description>
    </item>
    <item>
      <title>Cassandra Exporter</title>
      <link>http://localhost:1313/docsgo/monitor/exporter/cassandra-exporter/</link>
      <pubDate>Mon, 25 Mar 2024 09:26:56 +0800</pubDate>
      <guid>http://localhost:1313/docsgo/monitor/exporter/cassandra-exporter/</guid>
      <description>在cassandra 节点 - data1&#xA;下载包 wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.19.0/jmx_prometheus_javaagent-0.19.0.jar 放在data1:&#xA;mv jmx_prometheus_javaagent-0.19.0.jar /usr/share/cassandra/lib/ 2.1 配置修改1 /etc/cassandra/conf/cassandra-jmx.yaml&#xA;lowercaseOutputLabelNames: true lowercaseOutputName: true whitelistObjectNames: [&amp;#34;org.apache.cassandra.metrics:*&amp;#34;] # ColumnFamily is an alias for Table metrics blacklistObjectNames: [&amp;#34;org.apache.cassandra.metrics:type=ColumnFamily,*&amp;#34;] rules: # Generic gauges with 0-2 labels - pattern: org.apache.cassandra.metrics&amp;lt;type=(\S*)(?:, ((?!scope)\S*)=(\S*))?(?:, scope=(\S*))?, name=(\S*)&amp;gt;&amp;lt;&amp;gt;Value name: cassandra_$1_$5 type: GAUGE labels: &amp;#34;$1&amp;#34;: &amp;#34;$4&amp;#34; &amp;#34;$2&amp;#34;: &amp;#34;$3&amp;#34; # # Emulate Prometheus &amp;#39;Summary&amp;#39; metrics for the exported &amp;#39;Histogram&amp;#39;s. # TotalLatency is the sum of all latencies since server start # - pattern: org.</description>
    </item>
  </channel>
</rss>
